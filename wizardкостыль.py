import streamlit as st
import json
import os
import time
import gzip
import re
import io
from typing import TypedDict, Dict, List, Any
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from langgraph.graph import StateGraph
from google.generativeai import configure, GenerativeModel
import xml.etree.ElementTree as ET
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# PDF –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import pdfplumber
    PDF_LIB = "pdfplumber"
except ImportError:
    try:
        import fitz
        PDF_LIB = "pymupdf"
    except ImportError:
        PDF_LIB = None

# OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from pdf2image import convert_from_path
    import pytesseract
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

# Exa API –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –°–ú–ò
try:
    from exa_py import Exa
    EXA_AVAILABLE = True
except ImportError:
    EXA_AVAILABLE = False
    st.warning("‚ö†Ô∏è exa_py –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–∏—Å–∫ –≤ –°–ú–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install exa_py")

# PIL –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
st.set_page_config(page_title="–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏", page_icon="üìä", layout="wide")

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
EGRUL_API_URL_TEMPLATE = "https://egrul.itsoft.ru/{inn}.json.gz"
FIN_API_URL_TEMPLATE = "https://egrul.itsoft.ru/fin/?{inn}"
ARBITRATION_API_URL = "https://parser-api.com/parser/arbitr_api/search"
BASE_BOH_URL = "https://egrul.itsoft.ru/bo/"
ARBITRATION_API_KEY = os.getenv("ARBITRATION_API_KEY")
EXA_API_KEY = os.getenv("EXA_API_KEY")

configure(api_key=GEMINI_API_KEY)
model = GenerativeModel("gemini-2.5-flash")

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'application/json, text/html, */*',
    'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate'
}

class AgentState(TypedDict):
    inn: str
    egrul_parsed: dict
    fin_parsed: dict
    boh_parsed: list
    courts_parsed: dict
    related_companies: list
    media_mentions: list
    markdown_report: str

def normalize_inn(inn: str) -> str:
    inn = inn.strip()
    if len(inn) < 10:
        return inn.zfill(10)
    elif len(inn) < 12 and len(inn) > 10:
        return inn.zfill(12)
    return inn

def safe_get(data, *keys):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    for key in keys:
        if isinstance(data, dict):
            data = data.get(key)
        else:
            return None
        if data is None:
            return None
    return data

# ==================== –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–ê–†–°–ò–ù–ì PDF ====================

def _clean_number(num_str: str):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ä—É—Å—Å–∫–∏–µ/–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã —á–∏—Å–µ–ª –≤ float/int, —É—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –≤ —Å–∫–æ–±–∫–∞—Ö."""
    if not num_str:
        return None
    s = str(num_str)
    # –£–¥–∞–ª—è–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ñ—Ä—ã, –ø—Ä–æ–±–µ–ª—ã, –∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏, –º–∏–Ω—É—Å—ã, —Å–∫–æ–±–∫–∏
    s = s.replace('\xa0', ' ').replace('\u2009', ' ')
    s = s.strip()
    # –µ—Å–ª–∏ –≤ —Å–∫–æ–±–∫–∞—Ö ‚Äî –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ
    neg = False
    if re.match(r'^\(.*\)$', s):
        neg = True
        s = s.strip('()')
    # —É–±—Ä–∞—Ç—å –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, –∑–∞–ø—è—Ç–æ–π, —Ç–æ—á–∫–∏, –º–∏–Ω—É—Å–∞ –∏ –ø—Ä–æ–±–µ–ª–∞
    s = re.sub(r'[^0-9\-,\. ]+', '', s)
    # –∑–∞–º–µ–Ω–∏–º –ø—Ä–æ–±–µ–ª—ã –≤ —Ç—ã—Å—è—á–Ω—ã—Ö –Ω–∞ –ø—É—Å—Ç–æ
    s = s.replace(' ', '')
    # –∑–∞–º–µ–Ω–∏–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
    if ',' in s and '.' not in s:
        s = s.replace(',', '.')
    try:
        if s == '':
            return None
        if '.' in s:
            val = float(s)
        else:
            val = int(s)
        return -val if neg else val
    except:
        return None

def parse_accounting_from_text(text: str) -> dict:
    """
    –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ø–ª–æ—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    –ò—â–µ–º –±–ª–æ–∫–∏ '–ë–ê–õ–ê–ù–°' (–ê–∫—Ç–∏–≤/–ü–∞—Å—Å–∏–≤) –∏ '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã' (–í—ã—Ä—É—á–∫–∞, –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –∏ —Ç.–¥.)
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ—Ö–æ–∂—É—é –Ω–∞ parse_accounting_xml -> structured_data
    """
    res = {
        "report_type": None,
        "report_year": None,
        "company_info": {},
        "balance": {},
        "financial_results": {},
        "structured_data": {}
    }

    if not text or not text.strip():
        return res

    txt = text

    # 1) –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –≥–æ–¥: "–∑–∞ 2020 –≥.", "–∑–∞ 2020 –≥–æ–¥", "–∑–∞ 2020"
    year_match = re.search(r'–∑–∞\s+(\d{4})\s*(–≥–æ–¥|–≥\.)?', txt, flags=re.IGNORECASE)
    if not year_match:
        # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ - –ø–æ–∏—Å–∫ 4-–∑–Ω–∞—á–Ω–æ–≥–æ –≥–æ–¥–∞ —Ä—è–¥–æ–º —Å '–±–∞–ª–∞–Ω—Å' –∏–ª–∏ '–æ—Ç—á–µ—Ç'
        year_match = re.search(r'(–±–∞–ª–∞–Ω—Å|–æ—Ç—á–µ—Ç).{0,30}?(\d{4})', txt, flags=re.IGNORECASE)
    if year_match:
        res["report_year"] = year_match.group(1) if len(year_match.groups()) == 1 else year_match.group(2)

    # 2) –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –ò–ù–ù
    inn_match = re.search(r'–ò–ù–ù[:\s]*([0-9]{10,12})', txt, flags=re.IGNORECASE)
    if inn_match:
        res["company_info"]["inn"] = inn_match.group(1)

    # 3) –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ (—Å—Ç—Ä–æ–∫–∞ –ø–µ—Ä–µ–¥ –ò–ù–ù –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
    if inn_match:
        start = max(0, inn_match.start() - 200)
        snippet = txt[start:inn_match.start()]
        # –≤–æ–∑—å–º—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–º–Ω–æ–≥–æ—Å–∏–º–≤–æ–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É
        lines = [l.strip() for l in snippet.splitlines() if l.strip()]
        if lines:
            res["company_info"]["name"] = lines[-1][:200]

    # 4) –ë–ª–æ–∫–∏ –ë–∞–ª–∞–Ω—Å / –ê–∫—Ç–∏–≤ / –ü–∞—Å—Å–∏–≤
    # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ '–ë–ê–õ–ê–ù–°' –∏ '–ü–ê–°–°–ò–í'/'–ê–ö–¢–ò–í'
    bal_match = re.search(r'(–±–∞–ª–∞–Ω—Å|–ë–ê–õ–ê–ù–°)', txt, flags=re.IGNORECASE)
    if bal_match:
        res["report_type"] = "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π –±–∞–ª–∞–Ω—Å"
        # –≤–æ–∑—å–º—ë–º –æ–∫–Ω–æ —Ç–µ–∫—Å—Ç–∞ –≤–æ–∫—Ä—É–≥ –±–ª–æ–∫–∞ (—Å–ª—É—á–∞–π–Ω–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –≤–ø–µ—Ä–µ–¥)
        start = bal_match.start()
        window = txt[start:start+5000]
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫–∏ —Å —ç—Ç–∏–º–∏ –∫–ª—é—á–∞–º–∏ –∏ –ø–∞—Ä—Å–∏—Ç—å —á–∏—Å–ª–∞ —Å–ø—Ä–∞–≤–∞
        items = {
            "–í–Ω–µ–æ–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã": r'–í–Ω–µ–æ–±–æ—Ä–æ—Ç–Ω\w*\s+–∞–∫—Ç–∏–≤\w*\D*([0-9\-\(\)\s\.,]+)',
            "–ó–∞–ø–∞—Å—ã": r'–ó–∞–ø–∞—Å\w*\D*([0-9\-\(\)\s\.,]+)',
            "–î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": r'–î–µ–Ω–µ–∂–Ω\w*\s*—Å—Ä\w*\D*([0-9\-\(\)\s\.,]+)',
            "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è": r'–§–∏–Ω–∞–Ω\w*\s*–≤–ª–æ–∂\w*\D*([0-9\-\(\)\s\.,]+)',
            "–ù–µ–º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã": r'–ù–µ–º–∞—Ç–µ—Ä\w*\s*–∞–∫—Ç–∏–≤\w*\D*([0-9\-\(\)\s\.,]+)',
            "–ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã": r'–ö–∞–ø–∏—Ç–∞–ª\w*.*—Ä–µ–∑–µ—Ä–≤\w*\D*([0-9\-\(\)\s\.,]+)',
            "–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": r'–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω\w*\s*–∑–∞–µ–º\w*\s*—Å—Ä–µ–¥—Å—Ç–≤\D*([0-9\-\(\)\s\.,]+)',
            "–ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å": r'–ö—Ä–µ–¥–∏—Ç–æ—Ä\w*\s*–∑–∞–¥–æ–ª–∂\w*\D*([0-9\-\(\)\s\.,]+)'
        }
        active_details = {}
        passive_details = {}
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —è–≤–Ω—ã–µ –ø–∞—Ä—ã "label ... number" –≤ –æ–∫–Ω–µ
        for label, pattern in items.items():
            m = re.search(pattern, window, flags=re.IGNORECASE)
            if m:
                val = _clean_number(m.group(1))
                # —Ä–µ—à–∞–µ–º –∫—É–¥–∞ –∫–ª–∞—Å—Ç—å - –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ª–æ–≤—É "–∞–∫—Ç–∏–≤"/"–ø–∞—Å—Å–∏–≤" –≤ –ª–µ–π–±–ª–µ
                if re.search(r'–∞–∫—Ç–∏–≤', label, flags=re.IGNORECASE) or label in ["–í–Ω–µ–æ–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã","–î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞","–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è","–ù–µ–º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã","–ó–∞–ø–∞—Å—ã"]:
                    active_details[label] = val
                else:
                    passive_details[label] = val

        # –¢–∞–∫–∂–µ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ "–ò–¢–û–ì–û –ê–ö–¢–ò–í" –∏ "–ò–¢–û–ì–û –ü–ê–°–°–ò–í"
        total_active = re.search(r'(–∏—Ç–æ–≥\w*.*–∞–∫—Ç–∏–≤\w*|–≤—Å–µ–≥–æ.*–∞–∫—Ç–∏–≤\w*).{0,40}?([0-9\-\(\)\s\.,]+)', window, flags=re.IGNORECASE)
        total_passive = re.search(r'(–∏—Ç–æ–≥\w*.*–ø–∞—Å—Å–∏–≤\w*|–≤—Å–µ–≥–æ.*–ø–∞—Å—Å–∏–≤\w*).{0,40}?([0-9\-\(\)\s\.,]+)', window, flags=re.IGNORECASE)
        if total_active:
            res["balance"].setdefault("active", {})["total_current"] = _clean_number(total_active.group(2))
        if total_passive:
            res["balance"].setdefault("passive", {})["total_current"] = _clean_number(total_passive.group(2))

        if active_details:
            res["balance"].setdefault("active", {})["details"] = active_details
        if passive_details:
            res["balance"].setdefault("passive", {})["details"] = passive_details

    # 5) –§–∏–Ω—Ä–µ–∑ ‚Äî –í—ã—Ä—É—á–∫–∞ / –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å
    fin_patterns = {
        "revenue": r'–í—ã—Ä—É—á\w*\D*([0-9\-\(\)\s\.,]+)',
        "net_profit": r'–ß–∏—Å—Ç\w*\s*–ø—Ä–∏–±\w*\D*([0-9\-\(\)\s\.,]+)',
        "income_tax": r'–ù–∞–ª(–æ–≥)?\s*–Ω–∞\s*–ø—Ä–∏–±—ã–ª—å\D*([0-9\-\(\)\s\.,]+)',
        "expenses": r'–†–∞—Å—Ö\w*\D*([0-9\-\(\)\s\.,]+)'
    }
    for key, patt in fin_patterns.items():
        m = re.search(patt, txt, flags=re.IGNORECASE)
        if m:
            # –∏–Ω–æ–≥–¥–∞ –≥—Ä—É–ø–ø–∞ 1 - –Ω—É–∂–Ω–∞—è, –∏–Ω–æ–≥–¥–∞ 2 (–ø–æ—Å–ª–µ —Å–∫–æ–±–æ–∫). –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–Ω—É–ª–µ–≤—É—é
            grp = None
            if m.groups():
                # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É —Å–æ–¥–µ—Ä–∂–∞—â—É—é —Ü–∏—Ñ—Ä—ã
                for g in reversed(m.groups()):
                    if g and re.search(r'\d', str(g)):
                        grp = g
                        break
            if not grp:
                grp = m.group(1)
            res["financial_results"][key] = {"current": _clean_number(grp)}

    # 6) –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å ‚Äî –æ—Ç–º–µ—Ç–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ
    res["structured_data"] = {
        "balance": res.get("balance", {}),
        "financial_results": res.get("financial_results", {})
    }

    return res

def extract_from_pdf(pdf_path: str) -> dict:
    """
    –ú–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: pdfplumber -> pymupdf -> —Ç–∞–±–ª–∏—Ü—ã -> OCR.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å–æ 'text', 'success', –∏, –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, 'structured_data', 'report_type', 'report_year', 'company_info'
    """
    result = {
        "filename": os.path.basename(pdf_path),
        "success": False,
        "text": "",
        "structured_data": {},
        "report_type": None,
        "report_year": None,
        "company_info": {}
    }

    # 0) –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    try:
        with open(pdf_path, 'rb') as f:
            header = f.read(10)
            if not header.startswith(b'%PDF'):
                # –ø–æ–ø—Ä–æ–±—É–µ–º –∫–∞–∫ XML/—Ç–µ–∫—Å—Ç
                try:
                    with open(pdf_path, 'r', encoding='utf-8') as xf:
                        content = xf.read()
                        if '<?xml' in content or content.strip().startswith('<'):
                            return parse_accounting_xml(pdf_path)
                except:
                    pass
                result["error"] = f"–ù–µ PDF —Ñ–∞–π–ª. –ó–∞–≥–æ–ª–æ–≤–æ–∫: {header[:20]}"
                return result
    except Exception as e:
        result["error"] = f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}"
        return result
    
    # 0.5) –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ PDF (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü, –∑–∞—â–∏—Ç–∞)
    pdf_info = {}
    try:
        if PDF_LIB == "pdfplumber":
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                pdf_info["pages"] = len(pdf.pages)
                pdf_info["encrypted"] = pdf.metadata.get('Encrypted', False) if pdf.metadata else False
        elif PDF_LIB == "pymupdf":
            import fitz
            doc = fitz.open(pdf_path)
            pdf_info["pages"] = len(doc)
            pdf_info["encrypted"] = doc.is_encrypted
            doc.close()
        
        result["pdf_info"] = pdf_info
        
        if pdf_info.get("encrypted"):
            result["error"] = "PDF –∑–∞—â–∏—â–µ–Ω –ø–∞—Ä–æ–ª–µ–º –∏–ª–∏ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω"
            return result
            
        if pdf_info.get("pages", 0) == 0:
            result["error"] = "PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü"
            return result
            
    except Exception as e:
        result["pdf_diagnostic_error"] = str(e)

    extracted_text = []
    try:
        # 1) pdfplumber
        if PDF_LIB == "pdfplumber":
            try:
                import pdfplumber
                with pdfplumber.open(pdf_path) as pdf:
                    for page in pdf.pages:
                        # —Ç–µ–∫—Å—Ç
                        page_text = page.extract_text(x_tolerance=2, y_tolerance=2) or ""
                        # —Ç–∞–±–ª–∏—Ü—ã: –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–∞–±–ª–∏—Ü—ã –∫–∞–∫ fallback
                        try:
                            tables = page.extract_tables()
                            if tables:
                                # –ø–µ—Ä–µ–≤–µ–¥—ë–º —Ç–∞–±–ª–∏—Ü—ã –≤ —Å—Ç—Ä–æ–∫–∏
                                for t in tables:
                                    for row in t:
                                        row_text = " | ".join([c if c else "" for c in row])
                                        page_text += "\n" + row_text
                        except Exception:
                            pass
                        extracted_text.append(page_text)
            except Exception as e:
                # pdfplumber –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —É–ø–∞–ª ‚Äî –ø–µ—Ä–µ–π–¥—ë–º –∫ pymupdf
                extracted_text = []

        # 2) pymupdf (fitz)
        if (not extracted_text or all(not p.strip() for p in extracted_text)) and PDF_LIB == "pymupdf":
            try:
                import fitz
                doc = fitz.open(pdf_path)
                for i in range(len(doc)):
                    page = doc.load_page(i)
                    # get_text("blocks") –∏–ª–∏ "text" ‚Äî –ø—Ä–æ–±—É–µ–º "blocks" —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ —Å—ã—Ä—ã–µ –±–ª–æ–∫–∏
                    try:
                        text = page.get_text("text") or ""
                        if not text.strip():
                            # –ø–æ–ø—Ä–æ–±—É–µ–º blocks
                            blocks = page.get_text("blocks") or []
                            # blocks -> sort by y -> join
                            blocks_sorted = sorted(blocks, key=lambda b: b[1])
                            page_text = "\n".join([str(b[4]) for b in blocks_sorted if b and b[4]])
                        else:
                            page_text = text
                    except Exception:
                        page_text = page.get_text() or ""
                    extracted_text.append(page_text)
                doc.close()
            except Exception:
                pass

        # 3) –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º OCR —á–µ—Ä–µ–∑ pytesseract/pdf2image
        joined = "\n\n=== –ù–û–í–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===\n\n".join([p for p in extracted_text if p and p.strip()])
        
        if not joined.strip():
            result["extraction_method"] = "none"
            result["pages_processed"] = len(extracted_text)
            
            if OCR_AVAILABLE:
                # OCR fallback
                try:
                    from pdf2image import convert_from_path
                    import pytesseract
                    pages = convert_from_path(pdf_path, dpi=200)
                    ocr_texts = []
                    for page_im in pages:
                        txt = pytesseract.image_to_string(page_im, lang='rus+eng')
                        ocr_texts.append(txt)
                    joined = "\n\n=== –ù–û–í–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===\n\n".join(ocr_texts)
                    result["ocr_used"] = True
                    result["extraction_method"] = "ocr"
                except Exception as e:
                    # OCR —É–ø–∞–ª
                    result["error"] = f"OCR –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
                    return result
            else:
                # OCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                result["error"] = ("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç. –í–µ—Ä–æ—è—Ç–Ω–æ PDF ‚Äî —Å–∫–∞–Ω –±–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–ª–æ—è. "
                                   "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OCR: pip install pdf2image pytesseract")
                return result
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ —Å—Ä–∞–±–æ—Ç–∞–ª
            if PDF_LIB == "pdfplumber":
                result["extraction_method"] = "pdfplumber"
            elif PDF_LIB == "pymupdf":
                result["extraction_method"] = "pymupdf"
            else:
                result["extraction_method"] = "unknown"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç
        result["text"] = joined
        result["success"] = True

        # 4) –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç-–ø–∞—Ä—Å–µ—Ä –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏–∏
        try:
            parsed = parse_accounting_from_text(joined)
            if parsed:
                # –ú–µ—Ä–∂–∏–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–µ –ø–æ–ª—è
                result["structured_data"] = parsed.get("structured_data", {})
                result["report_type"] = parsed.get("report_type") or result.get("report_type")
                result["report_year"] = parsed.get("report_year") or result.get("report_year")
                result["company_info"] = parsed.get("company_info") or result.get("company_info")
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º multi_year_data –µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if result["structured_data"].get("balance") or result["structured_data"].get("financial_results"):
                    result["multi_year_data"] = {
                        "years": [result.get("report_year", "N/A")],
                        "balance": {},
                        "financial_results": {}
                    }
                    
                    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –±–∞–ª–∞–Ω—Å–∞
                    if result["structured_data"].get("balance"):
                        balance = result["structured_data"]["balance"]
                        if balance.get("active"):
                            active = balance["active"]
                            if active.get("total_current"):
                                result["multi_year_data"]["balance"]["–ê–ö–¢–ò–í (–≤—Å–µ–≥–æ)"] = [active.get("total_current")]
                            if active.get("details"):
                                for key, val in active["details"].items():
                                    result["multi_year_data"]["balance"][key] = [val]
                        
                        if balance.get("passive"):
                            passive = balance["passive"]
                            if passive.get("total_current"):
                                result["multi_year_data"]["balance"]["–ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ)"] = [passive.get("total_current")]
                            if passive.get("details"):
                                for key, val in passive["details"].items():
                                    result["multi_year_data"]["balance"][key] = [val]
                    
                    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Ñ–∏–Ω—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    if result["structured_data"].get("financial_results"):
                        fin_res = result["structured_data"]["financial_results"]
                        if fin_res.get("revenue"):
                            result["multi_year_data"]["financial_results"]["–í—ã—Ä—É—á–∫–∞"] = [fin_res["revenue"].get("current")]
                        if fin_res.get("net_profit"):
                            result["multi_year_data"]["financial_results"]["–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (—É–±—ã—Ç–æ–∫)"] = [fin_res["net_profit"].get("current")]
                        if fin_res.get("expenses"):
                            result["multi_year_data"]["financial_results"]["–†–∞—Å—Ö–æ–¥—ã"] = [fin_res["expenses"].get("current")]
                        if fin_res.get("income_tax"):
                            result["multi_year_data"]["financial_results"]["–ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å"] = [fin_res["income_tax"].get("current")]
        
        except Exception as e:
            # –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ ‚Äî –æ—Å—Ç–∞–≤–∏–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
            result["parsing_error"] = str(e)

    except Exception as e:
        result["error"] = str(e)
        result["success"] = False

    return result

# ==================== –ü–ê–†–°–ò–ù–ì XML –ë–£–•–û–¢–ß–ï–¢–ù–û–°–¢–ò ====================

def parse_accounting_xml(xml_path: str) -> dict:
    """
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è XML –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º—ã 0710001 (–ë–∞–ª–∞–Ω—Å) –∏ 0710002 (–§–∏–Ω—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
    """
    result = {
        "filename": os.path.basename(xml_path),
        "success": False,
        "report_type": None,
        "report_year": None,
        "company_info": {},
        "balance": {},
        "financial_results": {},
        "text": "",
        "structured_data": {}
    }
    
    try:
        # –ß–∏—Ç–∞–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
        with open(xml_path, 'r', encoding='windows-1251') as f:
            content = f.read()
        
        tree = ET.ElementTree(ET.fromstring(content))
        root = tree.getroot()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc = root.find('.//–î–æ–∫—É–º–µ–Ω—Ç')
        if doc is not None:
            result["report_year"] = doc.get('–û—Ç—á–µ—Ç–ì–æ–¥')
            result["report_date"] = doc.get('–î–∞—Ç–∞–î–æ–∫')
            okud = doc.get('–ö–ù–î')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—Ç—á–µ—Ç–∞
            if okud == "0710096":  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞
                result["report_type"] = "–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞"
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏
            svnp = doc.find('.//–°–≤–ù–ü')
            if svnp is not None:
                # –î–∞–Ω–Ω—ã–µ –æ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –ù–ü–Æ–õ (–Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫ —é—Ä. –ª–∏—Ü–æ)
                npul = svnp.find('.//–ù–ü–Æ–õ')
                if npul is not None:
                    company_attrs = npul.attrib
                    result["company_info"]["inn"] = company_attrs.get('–ò–ù–ù–Æ–õ')
                    result["company_info"]["kpp"] = company_attrs.get('–ö–ü–ü')
                    result["company_info"]["name"] = company_attrs.get('–ù–∞–∏–º–û—Ä–≥')
                    result["company_info"]["address"] = company_attrs.get('–ê–¥—Ä–ú–ù')
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –≤ –°–≤–ù–ü
                svnp_attrs = svnp.attrib
                result["company_info"]["okved"] = svnp_attrs.get('–û–ö–í–≠–î2')
                result["company_info"]["okopf"] = svnp_attrs.get('–û–ö–û–ü–§')
                result["company_info"]["okpo"] = svnp_attrs.get('–û–ö–ü–û')
                result["company_info"]["okfs"] = svnp_attrs.get('–û–ö–§–°')
            
            # –ü–æ–¥–ø–∏—Å–∞–Ω—Ç
            podp = doc.find('.//–ü–æ–¥–ø–∏—Å–∞–Ω—Ç')
            if podp is not None:
                fio = podp.find('.//–§–ò–û')
                if fio is not None:
                    result["company_info"]["signatory"] = {
                        "surname": fio.get('–§–∞–º–∏–ª–∏—è'),
                        "name": fio.get('–ò–º—è'),
                        "patronymic": fio.get('–û—Ç—á–µ—Å—Ç–≤–æ')
                    }
            
            # –ë–ê–õ–ê–ù–° (—Ñ–æ—Ä–º–∞ 0710001)
            balance = doc.find('.//–ë–∞–ª–∞–Ω—Å')
            if balance is not None:
                result["report_type"] = "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π –±–∞–ª–∞–Ω—Å"
                
                # –ê–ö–¢–ò–í
                active = balance.find('.//–ê–∫—Ç–∏–≤')
                if active is not None:
                    result["balance"]["active"] = {
                        "total_current": active.get('–°—É–º–û—Ç—á'),
                        "total_prev_year": active.get('–°—É–º–ü—Ä–¥–®–≤'),
                        "total_prev_2years": active.get('–°—É–º–ü—Ä–¥–©'),
                        "details": {}
                    }
                    
                    # –í–Ω–µ–æ–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã
                    mat_vne = active.find('.//–ú–∞—Ç–í–Ω–µ–ê–∫—Ç')
                    if mat_vne is not None:
                        result["balance"]["active"]["details"]["non_current_assets"] = {
                            "current": mat_vne.get('–°—É–º–û—Ç—á'),
                            "prev_year": mat_vne.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": mat_vne.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è
                    fin_vlozh = active.find('.//–§–∏–Ω–í–ª–æ–∂')
                    if fin_vlozh is not None:
                        result["balance"]["active"]["details"]["financial_investments"] = {
                            "current": fin_vlozh.get('–°—É–º–û—Ç—á'),
                            "prev_year": fin_vlozh.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": fin_vlozh.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –ó–∞–ø–∞—Å—ã
                    zapasy = active.find('.//–ó–∞–ø–∞—Å—ã')
                    if zapasy is not None:
                        result["balance"]["active"]["details"]["inventory"] = {
                            "current": zapasy.get('–°—É–º–û—Ç—á'),
                            "prev_year": zapasy.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": zapasy.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞
                    denezhn = active.find('.//–î–µ–Ω–µ–∂–Ω–°—Ä')
                    if denezhn is not None:
                        result["balance"]["active"]["details"]["cash"] = {
                            "current": denezhn.get('–°—É–º–û—Ç—á'),
                            "prev_year": denezhn.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": denezhn.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –ù–µ–º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∞–∫—Ç–∏–≤—ã
                    ne_mat = active.find('.//–ù–µ–ú–∞—Ç–§–∏–Ω–ê–∫—Ç')
                    if ne_mat is not None:
                        result["balance"]["active"]["details"]["intangible_assets"] = {
                            "current": ne_mat.get('–°—É–º–û—Ç—á'),
                            "prev_year": ne_mat.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": ne_mat.get('–°—É–º–ü—Ä–¥–©')
                        }
                
                # –ü–ê–°–°–ò–í
                passive = balance.find('.//–ü–∞—Å—Å–∏–≤')
                if passive is not None:
                    result["balance"]["passive"] = {
                        "total_current": passive.get('–°—É–º–û—Ç—á'),
                        "total_prev_year": passive.get('–°—É–º–ü—Ä–¥–®–≤'),
                        "total_prev_2years": passive.get('–°—É–º–ü—Ä–¥–©'),
                        "details": {}
                    }
                    
                    # –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã
                    kap_rez = passive.find('.//–ö–∞–ø–†–µ–∑')
                    if kap_rez is not None:
                        result["balance"]["passive"]["details"]["equity"] = {
                            "current": kap_rez.get('–°—É–º–û—Ç—á'),
                            "prev_year": kap_rez.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": kap_rez.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞
                    dlg_zaem = passive.find('.//–î–ª–≥–ó–∞–µ–º–°—Ä–µ–¥—Å—Ç–≤')
                    if dlg_zaem is not None:
                        result["balance"]["passive"]["details"]["long_term_debt"] = {
                            "current": dlg_zaem.get('–°—É–º–û—Ç—á'),
                            "prev_year": dlg_zaem.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": dlg_zaem.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –î—Ä—É–≥–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
                    dr_dolg = passive.find('.//–î—Ä–î–æ–ª–≥–æ—Å—Ä–û–±—è–∑')
                    if dr_dolg is not None:
                        result["balance"]["passive"]["details"]["other_long_term_liab"] = {
                            "current": dr_dolg.get('–°—É–º–û—Ç—á'),
                            "prev_year": dr_dolg.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": dr_dolg.get('–°—É–º–ü—Ä–¥–©')
                        }
                    
                    # –ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å
                    kredit = passive.find('.//–ö—Ä–µ–¥–∏—Ç–ó–∞–¥–æ–ª–∂')
                    if kredit is not None:
                        result["balance"]["passive"]["details"]["accounts_payable"] = {
                            "current": kredit.get('–°—É–º–û—Ç—á'),
                            "prev_year": kredit.get('–°—É–º–ü—Ä–¥–®–≤'),
                            "prev_2years": kredit.get('–°—É–º–ü—Ä–¥–©')
                        }
            
            # –û–¢–ß–ï–¢ –û –§–ò–ù–ê–ù–°–û–í–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–ê–• (—Ñ–æ—Ä–º–∞ 0710002)
            fin_rez = doc.find('.//–§–∏–Ω–†–µ–∑')
            if fin_rez is not None:
                if not result["report_type"]:
                    result["report_type"] = "–û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
                else:
                    result["report_type"] += " + –û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
                
                # –í—ã—Ä—É—á–∫–∞
                viruch = fin_rez.find('.//–í—ã—Ä—É—á')
                if viruch is not None:
                    result["financial_results"]["revenue"] = {
                        "current": viruch.get('–°—É–º–û—Ç—á'),
                        "previous": viruch.get('–°—É–º–ü—Ä–µ–¥')
                    }
                
                # –†–∞—Å—Ö–æ–¥—ã –ø–æ –æ–±—ã—á–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                rashod = fin_rez.find('.//–†–∞—Å—Ö–û–±–î–µ—è—Ç')
                if rashod is not None:
                    result["financial_results"]["expenses"] = {
                        "current": rashod.get('–°—É–º–û—Ç—á'),
                        "previous": rashod.get('–°—É–º–ü—Ä–µ–¥')
                    }
                
                # –ü—Ä–æ—á–∏–µ –¥–æ—Ö–æ–¥—ã
                proch_doh = fin_rez.find('.//–ü—Ä–æ—á–î–æ—Ö–æ–¥')
                if proch_doh is not None:
                    result["financial_results"]["other_income"] = {
                        "current": proch_doh.get('–°—É–º–û—Ç—á'),
                        "previous": proch_doh.get('–°—É–º–ü—Ä–µ–¥')
                    }
                
                # –ü—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã
                proch_rash = fin_rez.find('.//–ü—Ä–æ—á–†–∞—Å—Ö–æ–¥')
                if proch_rash is not None:
                    result["financial_results"]["other_expenses"] = {
                        "current": proch_rash.get('–°—É–º–û—Ç—á'),
                        "previous": proch_rash.get('–°—É–º–ü—Ä–µ–¥')
                    }
                
                # –ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å
                nal_prib = fin_rez.find('.//–ù–∞–ª–ü—Ä–∏–±–î–æ—Ö')
                if nal_prib is not None:
                    result["financial_results"]["income_tax"] = {
                        "current": nal_prib.get('–°—É–º–û—Ç—á'),
                        "previous": nal_prib.get('–°—É–º–ü—Ä–µ–¥')
                    }
                
                # –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫
                chist_prib = fin_rez.find('.//–ß–∏—Å—Ç–ü—Ä–∏–±–£–±')
                if chist_prib is not None:
                    result["financial_results"]["net_profit"] = {
                        "current": chist_prib.get('–°—É–º–û—Ç—á'),
                        "previous": chist_prib.get('–°—É–º–ü—Ä–µ–¥')
                    }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        text_parts = []
        text_parts.append(f"=== {result['report_type']} –∑–∞ {result['report_year']} –≥–æ–¥ ===\n")
        text_parts.append(f"–ö–æ–º–ø–∞–Ω–∏—è: {result['company_info'].get('name', 'N/A')}")
        text_parts.append(f"–ò–ù–ù: {result['company_info'].get('inn', 'N/A')}")
        text_parts.append(f"–ö–ü–ü: {result['company_info'].get('kpp', 'N/A')}\n")
        
        if result["balance"]:
            text_parts.append("\n--- –ë–ê–õ–ê–ù–° ---")
            if "active" in result["balance"]:
                text_parts.append(f"–ê–ö–¢–ò–í (–≤—Å–µ–≥–æ): {result['balance']['active'].get('total_current', 'N/A')} —Ç—ã—Å. —Ä—É–±.")
            if "passive" in result["balance"]:
                text_parts.append(f"–ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ): {result['balance']['passive'].get('total_current', 'N/A')} —Ç—ã—Å. —Ä—É–±.")
        
        if result["financial_results"]:
            text_parts.append("\n--- –§–ò–ù–ê–ù–°–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ ---")
            if "revenue" in result["financial_results"]:
                text_parts.append(f"–í—ã—Ä—É—á–∫–∞: {result['financial_results']['revenue'].get('current', 'N/A')} —Ç—ã—Å. —Ä—É–±.")
            if "net_profit" in result["financial_results"]:
                text_parts.append(f"–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å: {result['financial_results']['net_profit'].get('current', 'N/A')} —Ç—ã—Å. —Ä—É–±.")
        
        result["text"] = "\n".join(text_parts)
        result["structured_data"] = {
            "balance": result["balance"],
            "financial_results": result["financial_results"]
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –°–í–û–î–ù–û–ô –¢–ê–ë–õ–ò–¶–´ –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º
        multi_year = {"years": [], "balance": {}, "financial_results": {}}
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–¥—ã
        if result["report_year"]:
            try:
                year_current = int(result["report_year"])
                year_prev = year_current - 1
                year_prev2 = year_current - 2
                multi_year["years"] = [str(year_current), str(year_prev), str(year_prev2)]
            except:
                multi_year["years"] = [result["report_year"], "N/A", "N/A"]
        
        # –ë–ê–õ–ê–ù–° - —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        if result["balance"]:
            if "active" in result["balance"]:
                active = result["balance"]["active"]
                
                # –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–æ–≤
                multi_year["balance"]["–ê–ö–¢–ò–í (–≤—Å–µ–≥–æ)"] = [
                    active.get("total_current"),
                    active.get("total_prev_year"),
                    active.get("total_prev_2years")
                ]
                
                # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –∞–∫—Ç–∏–≤–æ–≤
                if "details" in active:
                    details = active["details"]
                    
                    if "non_current_assets" in details:
                        nca = details["non_current_assets"]
                        multi_year["balance"]["–í–Ω–µ–æ–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã"] = [
                            nca.get("current"),
                            nca.get("prev_year"),
                            nca.get("prev_2years")
                        ]
                    
                    if "financial_investments" in details:
                        fi = details["financial_investments"]
                        multi_year["balance"]["–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è"] = [
                            fi.get("current"),
                            fi.get("prev_year"),
                            fi.get("prev_2years")
                        ]
                    
                    if "inventory" in details:
                        inv = details["inventory"]
                        multi_year["balance"]["–ó–∞–ø–∞—Å—ã"] = [
                            inv.get("current"),
                            inv.get("prev_year"),
                            inv.get("prev_2years")
                        ]
                    
                    if "cash" in details:
                        cash = details["cash"]
                        multi_year["balance"]["–î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞"] = [
                            cash.get("current"),
                            cash.get("prev_year"),
                            cash.get("prev_2years")
                        ]
                    
                    if "intangible_assets" in details:
                        ia = details["intangible_assets"]
                        multi_year["balance"]["–ù–µ–º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã"] = [
                            ia.get("current"),
                            ia.get("prev_year"),
                            ia.get("prev_2years")
                        ]
            
            if "passive" in result["balance"]:
                passive = result["balance"]["passive"]
                
                # –í—Å–µ–≥–æ –ø–∞—Å—Å–∏–≤–æ–≤
                multi_year["balance"]["–ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ)"] = [
                    passive.get("total_current"),
                    passive.get("total_prev_year"),
                    passive.get("total_prev_2years")
                ]
                
                # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Å—Å–∏–≤–æ–≤
                if "details" in passive:
                    details = passive["details"]
                    
                    if "equity" in details:
                        eq = details["equity"]
                        multi_year["balance"]["–ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã"] = [
                            eq.get("current"),
                            eq.get("prev_year"),
                            eq.get("prev_2years")
                        ]
                    
                    if "long_term_debt" in details:
                        ltd = details["long_term_debt"]
                        multi_year["balance"]["–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞"] = [
                            ltd.get("current"),
                            ltd.get("prev_year"),
                            ltd.get("prev_2years")
                        ]
                    
                    if "other_long_term_liab" in details:
                        oltl = details["other_long_term_liab"]
                        multi_year["balance"]["–î—Ä—É–≥–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞"] = [
                            oltl.get("current"),
                            oltl.get("prev_year"),
                            oltl.get("prev_2years")
                        ]
                    
                    if "accounts_payable" in details:
                        ap = details["accounts_payable"]
                        multi_year["balance"]["–ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å"] = [
                            ap.get("current"),
                            ap.get("prev_year"),
                            ap.get("prev_2years")
                        ]
        
        # –§–ò–ù–ê–ù–°–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ (—Ç–æ–ª—å–∫–æ 2 –≥–æ–¥–∞: —Ç–µ–∫—É—â–∏–π –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π)
        if result["financial_results"]:
            fin_years = multi_year["years"][:2] if len(multi_year["years"]) >= 2 else multi_year["years"]
            
            if "revenue" in result["financial_results"]:
                rev = result["financial_results"]["revenue"]
                multi_year["financial_results"]["–í—ã—Ä—É—á–∫–∞"] = [
                    rev.get("current"),
                    rev.get("previous")
                ]
            
            if "expenses" in result["financial_results"]:
                exp = result["financial_results"]["expenses"]
                multi_year["financial_results"]["–†–∞—Å—Ö–æ–¥—ã –ø–æ –æ–±—ã—á–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"] = [
                    exp.get("current"),
                    exp.get("previous")
                ]
            
            if "other_income" in result["financial_results"]:
                oi = result["financial_results"]["other_income"]
                multi_year["financial_results"]["–ü—Ä–æ—á–∏–µ –¥–æ—Ö–æ–¥—ã"] = [
                    oi.get("current"),
                    oi.get("previous")
                ]
            
            if "other_expenses" in result["financial_results"]:
                oe = result["financial_results"]["other_expenses"]
                multi_year["financial_results"]["–ü—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã"] = [
                    oe.get("current"),
                    oe.get("previous")
                ]
            
            if "income_tax" in result["financial_results"]:
                it = result["financial_results"]["income_tax"]
                multi_year["financial_results"]["–ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å"] = [
                    it.get("current"),
                    it.get("previous")
                ]
            
            if "net_profit" in result["financial_results"]:
                np_val = result["financial_results"]["net_profit"]
                multi_year["financial_results"]["–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (—É–±—ã—Ç–æ–∫)"] = [
                    np_val.get("current"),
                    np_val.get("previous")
                ]
        
        result["multi_year_data"] = multi_year
        result["success"] = True
        
    except Exception as e:
        result["error"] = str(e)
        result["text"] = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {str(e)}"
    
    return result

def extract_from_xml(xml_path: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ XML - —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä"""
    
    # –ü—Ä–æ–±—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
    accounting_result = parse_accounting_xml(xml_path)
    if accounting_result.get("success"):
        return accounting_result
    
    # Fallback: –æ–±—â–∏–π –ø–∞—Ä—Å–µ—Ä
    result = {
        "filename": os.path.basename(xml_path),
        "success": False,
        "data": {},
        "text": ""
    }
    
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        elements = []
        for elem in root.iter():
            if elem.text and elem.text.strip():
                tag = elem.tag.split('}')[-1] if '}' in elem.tag else elem.tag
                elements.append(f"{tag}: {elem.text.strip()}")
        
        result["text"] = "\n".join(elements)
        result["data"]["elements_count"] = len(elements)
        result["data"]["root_tag"] = root.tag
        result["success"] = True
        
    except Exception as e:
        result["error"] = str(e)
    
    return result

def extract_from_pdf(pdf_path: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF"""
    result = {
        "filename": os.path.basename(pdf_path),
        "success": False,
        "text": ""
    }
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ PDF
        with open(pdf_path, 'rb') as f:
            header = f.read(10)
            if not header.startswith(b'%PDF'):
                # –ü—Ä–æ–±—É–µ–º –∫–∞–∫ XML
                try:
                    with open(pdf_path, 'r', encoding='utf-8') as xf:
                        content = xf.read()
                        if '<?xml' in content or content.strip().startswith('<'):
                            return extract_from_xml(pdf_path)
                except:
                    pass
                result["error"] = f"–ù–µ PDF. –ó–∞–≥–æ–ª–æ–≤–æ–∫: {header}"
                return result
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        if PDF_LIB == "pdfplumber":
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                texts = []
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        texts.append(text)
                result["text"] = "\n\n=== –ù–û–í–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===\n\n".join(texts)
                result["success"] = True
                
        elif PDF_LIB == "pymupdf":
            import fitz
            doc = fitz.open(pdf_path)
            texts = []
            for i in range(len(doc)):
                texts.append(doc[i].get_text())
            doc.close()
            result["text"] = "\n\n=== –ù–û–í–ê–Ø –°–¢–†–ê–ù–ò–¶–ê ===\n\n".join(texts)
            result["success"] = True
        else:
            result["error"] = "–ù–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è PDF"
        
    except Exception as e:
        result["error"] = str(e)
    
    return result

# ==================== –ü–ê–†–°–ò–ù–ì –ï–ì–†–Æ–õ ====================
def parse_egrul_data(egrul_json: dict) -> dict:
    """–ü–û–õ–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –ï–ì–†–Æ–õ JSON - –†–ï–ê–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê API"""
    parsed = {
        "raw_json_structure": list(egrul_json.keys()),
        "basic_info": {},
        "address": {},
        "directors": [],
        "founders": [],
        "okved": {},
        "capital": None,
        "all_fields": {},
        "related_companies": []
    }
    
    try:
        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä - –°–≤–Æ–õ (–°–≤–µ–¥–µ–Ω–∏—è –æ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–º –ª–∏—Ü–µ)
        svul = egrul_json.get("–°–≤–Æ–õ", {})
        if not svul:
            # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            svul = egrul_json
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã (–ò–ù–ù, –û–ì–†–ù –∏ —Ç.–¥.)
        attrs = svul.get("@attributes", {})
        parsed["basic_info"]["inn"] = attrs.get("–ò–ù–ù")
        parsed["basic_info"]["ogrn"] = attrs.get("–û–ì–†–ù")
        parsed["basic_info"]["kpp"] = attrs.get("–ö–ü–ü")
        parsed["basic_info"]["reg_date"] = attrs.get("–î–∞—Ç–∞–û–ì–†–ù")
        parsed["basic_info"]["data_extract_date"] = attrs.get("–î–∞—Ç–∞–í—ã–ø")
        
        # –û–ü–§ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ-–ø—Ä–∞–≤–æ–≤–∞—è —Ñ–æ—Ä–º–∞)
        parsed["basic_info"]["opf_code"] = attrs.get("–ö–æ–¥–û–ü–§")
        parsed["basic_info"]["opf_full"] = attrs.get("–ü–æ–ª–Ω–ù–∞–∏–º–û–ü–§")
        
        # –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
        sv_naim = svul.get("–°–≤–ù–∞–∏–º–Æ–õ", {})
        naim_attrs = sv_naim.get("@attributes", {})
        parsed["basic_info"]["full_name"] = naim_attrs.get("–ù–∞–∏–º–Æ–õ–ü–æ–ª–Ω")
        
        # –ö–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
        sv_naim_sokr = sv_naim.get("–°–≤–ù–∞–∏–º–Æ–õ–°–æ–∫—Ä", {})
        if isinstance(sv_naim_sokr, dict):
            sokr_attrs = sv_naim_sokr.get("@attributes", {})
            parsed["basic_info"]["short_name"] = sokr_attrs.get("–ù–∞–∏–º–°–æ–∫—Ä")
        
        parsed["all_fields"] = parsed["basic_info"].copy()
        
        # –ê–¥—Ä–µ—Å
        sv_addr = svul.get("–°–≤–ê–¥—Ä–µ—Å–Æ–õ", {})
        addr_rf = sv_addr.get("–ê–¥—Ä–µ—Å–†–§", {})
        if addr_rf:
            addr_attrs = addr_rf.get("@attributes", {})
            region_info = addr_rf.get("–†–µ–≥–∏–æ–Ω", {}).get("@attributes", {})
            street_info = addr_rf.get("–£–ª–∏—Ü–∞", {}).get("@attributes", {})
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å
            address_parts = []
            if addr_attrs.get("–ò–Ω–¥–µ–∫—Å"):
                address_parts.append(addr_attrs["–ò–Ω–¥–µ–∫—Å"])
            if region_info.get("–ù–∞–∏–º–†–µ–≥–∏–æ–Ω"):
                address_parts.append(region_info["–ù–∞–∏–º–†–µ–≥–∏–æ–Ω"])
            if street_info.get("–¢–∏–ø–£–ª–∏—Ü–∞") and street_info.get("–ù–∞–∏–º–£–ª–∏—Ü–∞"):
                address_parts.append(f"{street_info['–¢–∏–ø–£–ª–∏—Ü–∞']} {street_info['–ù–∞–∏–º–£–ª–∏—Ü–∞']}")
            if addr_attrs.get("–î–æ–º"):
                address_parts.append(f"–¥. {addr_attrs['–î–æ–º']}")
            if addr_attrs.get("–ö–æ—Ä–ø—É—Å"):
                address_parts.append(f"–∫–æ—Ä–ø. {addr_attrs['–ö–æ—Ä–ø—É—Å']}")
            if addr_attrs.get("–ö–≤–∞—Ä—Ç"):
                address_parts.append(f"–∫–≤. {addr_attrs['–ö–≤–∞—Ä—Ç']}")
            
            parsed["address"] = {
                "index": addr_attrs.get("–ò–Ω–¥–µ–∫—Å"),
                "region": region_info.get("–ù–∞–∏–º–†–µ–≥–∏–æ–Ω"),
                "street_type": street_info.get("–¢–∏–ø–£–ª–∏—Ü–∞"),
                "street": street_info.get("–ù–∞–∏–º–£–ª–∏—Ü–∞"),
                "house": addr_attrs.get("–î–æ–º"),
                "corpus": addr_attrs.get("–ö–æ—Ä–ø—É—Å"),
                "apartment": addr_attrs.get("–ö–≤–∞—Ä—Ç"),
                "full": ", ".join(address_parts) if address_parts else None
            }
        
        # –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ (–°–≤–µ–¥–î–æ–ª–∂–Ω–§–õ)
        directors_data = svul.get("–°–≤–µ–¥–î–æ–ª–∂–Ω–§–õ", [])
        if not isinstance(directors_data, list):
            directors_data = [directors_data] if directors_data else []
        
        for director in directors_data:
            sv_fl = director.get("–°–≤–§–õ", {})
            fl_attrs = sv_fl.get("@attributes", {})
            
            sv_dolzhn = director.get("–°–≤–î–æ–ª–∂–Ω", {})
            dolzhn_attrs = sv_dolzhn.get("@attributes", {})
            
            full_name = f"{fl_attrs.get('–§–∞–º–∏–ª–∏—è', '')} {fl_attrs.get('–ò–º—è', '')} {fl_attrs.get('–û—Ç—á–µ—Å—Ç–≤–æ', '')}".strip()
            
            parsed["directors"].append({
                "surname": fl_attrs.get("–§–∞–º–∏–ª–∏—è"),
                "name": fl_attrs.get("–ò–º—è"),
                "patronymic": fl_attrs.get("–û—Ç—á–µ—Å—Ç–≤–æ"),
                "full_name": full_name,
                "position": dolzhn_attrs.get("–ù–∞–∏–º–î–æ–ª–∂–Ω"),
                "inn": fl_attrs.get("–ò–ù–ù–§–õ")
            })
        
        # –£—á—Ä–µ–¥–∏—Ç–µ–ª–∏
        sv_uchredit = svul.get("–°–≤–£—á—Ä–µ–¥–∏—Ç", {})
        
        # –§–∏–∑–ª–∏—Ü–∞-—É—á—Ä–µ–¥–∏—Ç–µ–ª–∏
        uchr_fl = sv_uchredit.get("–£—á—Ä–§–õ", [])
        if not isinstance(uchr_fl, list):
            uchr_fl = [uchr_fl] if uchr_fl else []
        
        for founder in uchr_fl:
            sv_fl = founder.get("–°–≤–§–õ", {})
            fl_attrs = sv_fl.get("@attributes", {})
            
            dolya = founder.get("–î–æ–ª—è–£—Å—Ç–ö–∞–ø", {})
            razmer_doli = dolya.get("–†–∞–∑–º–µ—Ä–î–æ–ª–∏", {})
            
            full_name = f"{fl_attrs.get('–§–∞–º–∏–ª–∏—è', '')} {fl_attrs.get('–ò–º—è', '')} {fl_attrs.get('–û—Ç—á–µ—Å—Ç–≤–æ', '')}".strip()
            
            parsed["founders"].append({
                "type": "–§–õ",
                "surname": fl_attrs.get("–§–∞–º–∏–ª–∏—è"),
                "name": fl_attrs.get("–ò–º—è"),
                "patronymic": fl_attrs.get("–û—Ç—á–µ—Å—Ç–≤–æ"),
                "full_name": full_name,
                "inn": fl_attrs.get("–ò–ù–ù–§–õ"),
                "share": razmer_doli.get("–ü—Ä–æ—Ü–µ–Ω—Ç"),
                "nominal_value": dolya.get("@attributes", {}).get("–ù–æ–º–∏–Ω–°—Ç–æ–∏–º")
            })
        
        # –Æ—Ä–ª–∏—Ü–∞-—É—á—Ä–µ–¥–∏—Ç–µ–ª–∏ (–¥–ª—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π)
        uchr_ul = sv_uchredit.get("–£—á—Ä–Æ–õ", [])
        if not isinstance(uchr_ul, list):
            uchr_ul = [uchr_ul] if uchr_ul else []
        
        for founder in uchr_ul:
            sv_ul = founder.get("–°–≤–Æ–õ", {})
            ul_attrs = sv_ul.get("@attributes", {})
            
            dolya = founder.get("–î–æ–ª—è–£—Å—Ç–ö–∞–ø", {})
            razmer_doli = dolya.get("–†–∞–∑–º–µ—Ä–î–æ–ª–∏", {})
            
            founder_inn = ul_attrs.get("–ò–ù–ù–Æ–õ")
            founder_name = ul_attrs.get("–ù–∞–∏–º–Æ–õ")
            share = razmer_doli.get("–ü—Ä–æ—Ü–µ–Ω—Ç")
            
            parsed["founders"].append({
                "type": "–Æ–õ",
                "name": founder_name,
                "inn": founder_inn,
                "ogrn": ul_attrs.get("–û–ì–†–ù"),
                "share": share,
                "nominal_value": dolya.get("@attributes", {}).get("–ù–æ–º–∏–Ω–°—Ç–æ–∏–º")
            })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
            if founder_inn:
                parsed["related_companies"].append({
                    "inn": founder_inn,
                    "name": founder_name,
                    "ogrn": ul_attrs.get("–û–ì–†–ù"),
                    "relation": "–£—á—Ä–µ–¥–∏—Ç–µ–ª—å",
                    "share": share
                })
        
        # –û–ö–í–≠–î
        sv_okved = svul.get("–°–≤–û–ö–í–≠–î", {})
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –û–ö–í–≠–î
        okved_osn = sv_okved.get("–°–≤–û–ö–í–≠–î–û—Å–Ω", {})
        if okved_osn:
            osn_attrs = okved_osn.get("@attributes", {})
            parsed["okved"]["main_code"] = osn_attrs.get("–ö–æ–¥–û–ö–í–≠–î")
            parsed["okved"]["main_name"] = osn_attrs.get("–ù–∞–∏–º–û–ö–í–≠–î")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –û–ö–í–≠–î
        okved_dop = sv_okved.get("–°–≤–û–ö–í–≠–î–î–æ–ø", [])
        if not isinstance(okved_dop, list):
            okved_dop = [okved_dop] if okved_dop else []
        
        parsed["okved"]["additional"] = []
        for okved in okved_dop:
            okved_attrs = okved.get("@attributes", {})
            parsed["okved"]["additional"].append({
                "code": okved_attrs.get("–ö–æ–¥–û–ö–í–≠–î"),
                "name": okved_attrs.get("–ù–∞–∏–º–û–ö–í–≠–î")
            })
        
        # –£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª
        sv_ust_kap = svul.get("–°–≤–£—Å—Ç–ö–∞–ø", {})
        if sv_ust_kap:
            kap_attrs = sv_ust_kap.get("@attributes", {})
            parsed["capital"] = kap_attrs.get("–°—É–º–ö–∞–ø")
        
    except Exception as e:
        parsed["parsing_error"] = str(e)
        import traceback
        parsed["parsing_traceback"] = traceback.format_exc()
    
    return parsed

# ==================== –ü–û–°–¢–†–û–ï–ù–ò–ï –ì–†–ê–§–ê –°–í–Ø–ó–ï–ô ====================
def build_company_network_diagram(company_info: dict, related_companies: list) -> str:
    """–°—Ç—Ä–æ–∏—Ç Mermaid –¥–∏–∞–≥—Ä–∞–º–º—É —Å–µ—Ç–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π"""
    company_name = company_info.get("short_name") or company_info.get("full_name") or "–ö–æ–º–ø–∞–Ω–∏—è"
    company_inn = company_info.get("inn") or "N/A"
    
    def clean_name(name):
        if not name:
            return "N/A"
        return name.replace('"', '').replace('[', '').replace(']', '').replace('(', '').replace(')', '')[:50]
    
    diagram = "```mermaid\ngraph TD\n"
    
    # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    main_label = f"{clean_name(company_name)}<br/>–ò–ù–ù: {company_inn}"
    
    diagram += f'    MAIN["{main_label}"]\n'
    diagram += "    style MAIN fill:#4CAF50,stroke:#2E7D32,stroke-width:3px,color:#fff\n\n"
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
    if related_companies:
        for idx, company in enumerate(related_companies, 1):
            node_id = f"REL{idx}"
            rel_name = clean_name(company.get("name"))
            rel_inn = company.get("inn", "N/A")
            relation = company.get("relation", "–°–≤—è–∑—å")
            share = company.get("share", "")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–≤—è–∑–∏
            if "–£—á—Ä–µ–¥–∏—Ç–µ–ª—å" in relation:
                color = "#2196F3"
                stroke = "#1565C0"
                arrow_label = "–í–ª–∞–¥–µ–µ—Ç"
            elif "–î–æ—á–µ—Ä–Ω" in relation:
                color = "#FF9800"
                stroke = "#E65100"
                arrow_label = "–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç"
            else:
                color = "#9E9E9E"
                stroke = "#616161"
                arrow_label = "–°–≤—è–∑—å"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç–∫—É —É–∑–ª–∞
            node_label = f"{rel_name}<br/>–ò–ù–ù: {rel_inn}<br/>{relation}"
            if share:
                node_label += f'<br/>üìä –î–æ–ª—è: {share}%'
            
            diagram += f'    {node_id}["{node_label}"]\n'
            diagram += f'    style {node_id} fill:{color},stroke:{stroke},stroke-width:2px,color:#fff\n'
            
            # –°–≤—è–∑—å —Å–æ —Å—Ç—Ä–µ–ª–∫–æ–π
            if "–£—á—Ä–µ–¥–∏—Ç–µ–ª—å" in relation:
                if share:
                    diagram += f'    {node_id} -->|{arrow_label} {share}%| MAIN\n'
                else:
                    diagram += f'    {node_id} -->|{arrow_label}| MAIN\n'
            else:
                diagram += f'    MAIN -->|{arrow_label}| {node_id}\n'
    else:
        diagram += '    NOTE["‚ùå –°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã<br/>–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –ï–ì–†–Æ–õ"]\n'
        diagram += '    style NOTE fill:#FFC107,stroke:#FF6F00,stroke-width:2px,color:#333\n'
        diagram += '    NOTE -.->|–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö| MAIN\n'
    
    diagram += "```\n"
    return diagram

# ==================== –ü–ê–†–°–ò–ù–ì –§–ò–ù–ê–ù–°–û–í ====================
def parse_financial_data(fin_json: dict) -> dict:
    """–ü–û–õ–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–Ω–∞–Ω—Å–æ–≤ - –†–ï–ê–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê API"""
    parsed = {
        "raw_json_structure": list(fin_json.keys()) if isinstance(fin_json, dict) else [],
        "income_expenses": [],
        "taxes": [],
        "employees": [],
        "tax_systems": [],
        "company_size": None,
        "support": [],
        "msp_status": [],
        "all_data": {}
    }
    
    try:
        # –ö–æ–¥—ã –Ω–∞–ª–æ–≥–æ–≤ (—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫)
        TAX_CODES = {
            "1": "–ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π / –£–°–ù",
            "2": "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–π –Ω–∞–ª–æ–≥",
            "3": "–ó–µ–º–µ–ª—å–Ω—ã–π –Ω–∞–ª–æ–≥",
            "5": "–°—Ç—Ä–∞—Ö–æ–≤—ã–µ –≤–∑–Ω–æ—Å—ã"
        }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥–æ–¥–∞–º
        years_data = {}
        for key, value in fin_json.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –≥–æ–¥ (—Ü–∏—Ñ—Ä—ã)
            if key.isdigit() and isinstance(value, dict):
                year = key
                year_data = value
                
                # –î–æ—Ö–æ–¥—ã/—Ä–∞—Å—Ö–æ–¥—ã
                income = year_data.get("income")
                outcome = year_data.get("outcome")
                
                if income or outcome:
                    parsed["income_expenses"].append({
                        "year": year,
                        "income": int(income) if income else None,
                        "outcome": int(outcome) if outcome else None,
                        "profit": (int(income) - int(outcome)) if (income and outcome) else None
                    })
                
                # –ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å
                n = year_data.get("n")
                if n:
                    parsed["employees"].append({
                        "year": year,
                        "count": int(n) if n else None
                    })
                
                # –°–∏—Å—Ç–µ–º–∞ –Ω–∞–ª–æ–≥–æ–æ–±–ª–æ–∂–µ–Ω–∏—è
                tax_system = year_data.get("tax_system")
                if tax_system:
                    tax_system_name = "–£–°–ù" if tax_system == "2" else f"–ö–æ–¥ {tax_system}"
                    if tax_system_name not in parsed["tax_systems"]:
                        parsed["tax_systems"].append({
                            "code": tax_system,
                            "name": tax_system_name
                        })
                
                # –ù–∞–ª–æ–≥–∏
                taxes = year_data.get("tax", {})
                if isinstance(taxes, dict):
                    for tax_code, tax_amount in taxes.items():
                        parsed["taxes"].append({
                            "year": year,
                            "code": tax_code,
                            "name": TAX_CODES.get(tax_code, f"–ù–∞–ª–æ–≥ –∫–æ–¥ {tax_code}"),
                            "amount": int(tax_amount) if tax_amount else None
                        })
                
                years_data[year] = year_data
        
        # –ú–°–ü —Å—Ç–∞—Ç—É—Å
        msp = fin_json.get("msp", [])
        if isinstance(msp, list):
            for item in msp:
                cat_name = {
                    "1": "–ú–∏–∫—Ä–æ–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ",
                    "2": "–ú–∞–ª–æ–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ", 
                    "3": "–°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ"
                }.get(str(item.get("cat")), f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {item.get('cat')}")
                
                parsed["msp_status"].append({
                    "date": item.get("inc_date"),
                    "category": cat_name,
                    "category_code": item.get("cat")
                })
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–º–ø–∞–Ω–∏–∏ (–±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π)
                parsed["company_size"] = cat_name
        
        # –ì–æ—Å–ø–æ–¥–¥–µ—Ä–∂–∫–∞
        support = fin_json.get("support", [])
        if isinstance(support, list):
            for item in support:
                # –§–æ—Ä–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
                form_names = {
                    "100": "–°—É–±—Å–∏–¥–∏—è",
                    "200": "–ì—Ä–∞–Ω—Ç",
                    "400": "–õ—å–≥–æ—Ç–∞"
                }
                
                # –¢–∏–ø—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
                type_names = {
                    "103": "–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞",
                    "204": "–ì—Ä–∞–Ω—Ç –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ",
                    "401": "–ù–∞–ª–æ–≥–æ–≤—ã–µ –ª—å–≥–æ—Ç—ã",
                    "406": "–õ—å–≥–æ—Ç–Ω—ã–µ –∫—Ä–µ–¥–∏—Ç—ã"
                }
                
                form_id = item.get("form_id")
                type_id = item.get("type_id")
                
                parsed["support"].append({
                    "year": item.get("accept_date", "")[:4] if item.get("accept_date") else None,
                    "from_inn": item.get("from_inn"),
                    "form": form_names.get(form_id, f"–§–æ—Ä–º–∞ {form_id}"),
                    "form_code": form_id,
                    "type": type_names.get(type_id, f"–¢–∏–ø {type_id}"),
                    "type_code": type_id,
                    "amount": float(item.get("s", 0)) if item.get("s") else None,
                    "amount_type": item.get("s_type"),
                    "accept_date": item.get("accept_date"),
                    "term": item.get("term"),
                    "end_date": item.get("end_date")
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥–æ–¥–∞–º (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ)
        parsed["income_expenses"].sort(key=lambda x: x["year"], reverse=True)
        parsed["taxes"].sort(key=lambda x: x["year"], reverse=True)
        parsed["employees"].sort(key=lambda x: x["year"], reverse=True)
        
        parsed["all_data"] = {
            "years_count": len(years_data),
            "years": sorted(years_data.keys(), reverse=True)
        }
        
    except Exception as e:
        parsed["parsing_error"] = str(e)
        import traceback
        parsed["parsing_traceback"] = traceback.format_exc()
    
    return parsed

# ==================== –§–£–ù–ö–¶–ò–ò –°–ë–û–†–ê –î–ê–ù–ù–´–• ====================
def fetch_egrul_data(state: AgentState) -> AgentState:
    inn = normalize_inn(state["inn"])
    url = EGRUL_API_URL_TEMPLATE.format(inn=inn)
    
    st.info(f"üìã –ó–∞–≥—Ä—É–∂–∞—é –ï–ì–†–Æ–õ –¥–ª—è {inn}...")
    time.sleep(10)
    
    for attempt in range(3):
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            try:
                content = gzip.decompress(response.content)
                raw_data = json.loads(content.decode('utf-8'))
            except:
                raw_data = response.json()
            
            # –ü–ê–†–°–ò–ú
            parsed_data = parse_egrul_data(raw_data)
            st.success(f"‚úÖ –ï–ì–†–Æ–õ: –Ω–∞–π–¥–µ–Ω–æ {len(parsed_data['raw_json_structure'])} –ø–æ–ª–µ–π")
            
            return {
                "egrul_parsed": parsed_data,
                "related_companies": parsed_data.get("related_companies", [])
            }
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:
                wait = 60 * (attempt + 1)
                st.warning(f"‚ö†Ô∏è 429. –ñ–¥–µ–º {wait} —Å–µ–∫...")
                time.sleep(wait)
                if attempt == 2:
                    return {"egrul_parsed": {"error": "429"}, "related_companies": []}
            else:
                return {"egrul_parsed": {"error": f"HTTP {e.response.status_code}"}, "related_companies": []}
        except Exception as e:
            return {"egrul_parsed": {"error": str(e)}, "related_companies": []}

def fetch_financial_data(state: AgentState) -> AgentState:
    inn = normalize_inn(state["inn"])
    url = FIN_API_URL_TEMPLATE.format(inn=inn)
    
    st.info(f"üí∞ –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∏–Ω–∞–Ω—Å—ã –¥–ª—è {inn}...")
    time.sleep(15)
    
    for attempt in range(3):
        try:
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            try:
                raw_data = response.json()
            except:
                content = gzip.decompress(response.content)
                raw_data = json.loads(content.decode('utf-8'))
            
            parsed_data = parse_financial_data(raw_data)
            st.success(f"‚úÖ –§–∏–Ω–∞–Ω—Å—ã: –Ω–∞–π–¥–µ–Ω–æ {len(parsed_data['raw_json_structure'])} –ø–æ–ª–µ–π")
            return {"fin_parsed": parsed_data}
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:
                wait = 60 * (attempt + 1)
                st.warning(f"‚ö†Ô∏è 429. –ñ–¥–µ–º {wait} —Å–µ–∫...")
                time.sleep(wait)
                if attempt == 2:
                    return {"fin_parsed": {"error": "429"}}
            else:
                return {"fin_parsed": {"error": f"HTTP {e.response.status_code}"}}
        except Exception as e:
            return {"fin_parsed": {"error": str(e)}}

def analyze_pdf_with_gemini(pdf_path: str, filename: str) -> dict:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç PDF –Ω–∞–ø—Ä—è–º—É—é –≤ Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–∫ –∏–Ω–≤–µ—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫
    """
    result = {
        "filename": filename,
        "success": False,
        "report_type": None,
        "report_year": None,
        "company_info": {},
        "multi_year_data": None,
        "analysis": None
    }
    
    try:
        # –ß–∏—Ç–∞–µ–º PDF –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        with open(pdf_path, 'rb') as f:
            pdf_data = f.read()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64 –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ API
        import base64
        pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è Gemini –∫–∞–∫ –∏–Ω–≤–µ—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        prompt = """–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω–≤–µ—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫—É—é –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å.

**–¢–≤–æ—è –∑–∞–¥–∞—á–∞:**
1. –ò–∑–≤–ª–µ—á—å –í–°–ï —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
2. –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
3. –î–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è

**–í–ï–†–ù–ò –¢–û–õ–¨–ö–û –í–ê–õ–ò–î–ù–´–ô JSON –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:**

```json
{
  "report_type": "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π –±–∞–ª–∞–Ω—Å" –∏–ª–∏ "–û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö" –∏–ª–∏ "–û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏" –∏–ª–∏ "–û—Ç—á–µ—Ç –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤" –∏–ª–∏ "–û—Ç—á–µ—Ç –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ –∫–∞–ø–∏—Ç–∞–ª–µ" –∏–ª–∏ "–ü–æ–ª–Ω–∞—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å",
  "report_year": "2023",
  "company_info": {
    "name": "–û–û–û –ö–û–ú–ü–ê–ù–ò–Ø",
    "inn": "1234567890"
  },
  "multi_year_data": {
    "years": ["2021", "2022", "2023"],
    "balance": {
      "–ê–ö–¢–ò–í (–≤—Å–µ–≥–æ)": [4500, 5200, 6047],
      "–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": [2800, 3200, 3800],
      "–ó–∞–ø–∞—Å—ã": [400, 500, 597],
      "–î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å": [600, 700, 850],
      "–î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": [150, 180, 192],
      "–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è": [100, 120, 128],
      "–ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ)": [4500, 5200, 6047],
      "–ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã": [3800, 4500, 5145],
      "–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": [200, 120, 250],
      "–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞": [50, 30, 50],
      "–ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å": [450, 550, 602],
      "–û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª": [750, 900, 1080],
      "–û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞, %": [1.67, 1.88, 2.06],
      "–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∑–∞–ø–∞—Å–æ–≤, —Ä–∞–∑": [112.5, 96.0, 87.9],
      "–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑": [75.0, 68.6, 61.8],
      "–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑": [100.0, 87.3, 87.2],
      "–ß–∏—Å—Ç—ã–π –¥–æ–ª–≥": [100, -30, 108],
      "–ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å, x": [0.06, -0.02, 0.05]
    },
    "financial_results": {
      "–í—ã—Ä—É—á–∫–∞": [45000, 48000, 52489],
      "–¢–µ–º–ø —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏, %": [null, 6.67, 9.35],
      "–í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å": [5000, 5500, 6100],
      "–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–∞–ª–æ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏, %": [11.11, 11.46, 11.63],
      "–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å": [1800, 2100, 2353],
      "–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, %": [4.00, 4.38, 4.48],
      "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (—É–±—ã—Ç–æ–∫)": [1800, 2100, 2353],
      "–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏, %": [4.00, 4.38, 4.48],
      "–ù–∞–ª–æ–≥ –Ω–∞ –ø—Ä–∏–±—ã–ª—å": [600, 750, 850]
    },
    "cash_flows": {
      "–°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏": [2500, 2800, 3100],
      "–°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏": [-800, -900, -1000],
      "–°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏": [-500, -600, -700],
      "–ò—Ç–æ–≥–æ–≤—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥": [1200, 1300, 1400],
      "–ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤": [600, 700, 800],
      "–†–∞–∑–Ω–∏—Ü–∞: –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ - –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –û–°": [1900, 2100, 2300]
    }
  },
  "analysis": {
    "financial_health": "–û—Ç–ª–∏—á–Ω–æ–µ/–•–æ—Ä–æ—à–µ–µ/–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ/–ü–ª–æ—Ö–æ–µ",
    "key_metrics": {
      "revenue_growth": "+9.3%",
      "profit_margin": "4.5%",
      "roa": "8.2%",
      "roe": "15.6%",
      "debt_to_equity": "0.18",
      "current_ratio": "2.8",
      "quick_ratio": "2.1"
    },
    "strengths": [
      "–°—Ç–∞–±–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç –≤—ã—Ä—É—á–∫–∏",
      "–ù–∏–∑–∫–∞—è –¥–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞",
      "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–∏–±—ã–ª–∏",
      "–í—ã—Å–æ–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å"
    ],
    "weaknesses": [
      "–†–æ—Å—Ç –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏",
      "–°–Ω–∏–∂–µ–Ω–∏–µ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç–∏ –∞–∫—Ç–∏–≤–æ–≤"
    ],
    "risks": [
      "–í–æ–∑–º–æ–∂–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏—è",
      "–°–Ω–∏–∂–µ–Ω–∏–µ –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"
    ],
    "investment_rating": "A/A-/B+/B/B-/C",
    "investment_recommendation": "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π / –¢—Ä–µ–±—É–µ—Ç –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏ / –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è",
    "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ü–∏—Ñ—Ä–∞–º–∏)"
  }
}
```

**–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:**
- –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –æ—Å—Ç–∞–≤–ª—è–π –ø–æ–ª–µ –ø—É—Å—Ç—ã–º –∏–ª–∏ null
- –í—Å–µ —Å—É–º–º—ã —É–∫–∞–∑—ã–≤–∞–π –≤ —Ç—ã—Å—è—á–∞—Ö —Ä—É–±–ª–µ–π (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)
- –†–∞—Å—Å—á–∏—Ç–∞–π –í–°–ï —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã:

**–ò–∑ –æ—Ç—á–µ—Ç–∞ –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö:**
  * –í—ã—Ä—É—á–∫–∞ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –¢–µ–º–ø —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏, % = ((–í—ã—Ä—É—á–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –≥–æ–¥–∞ - –í—ã—Ä—É—á–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≥–æ–¥–∞) / –í—ã—Ä—É—á–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≥–æ–¥–∞) * 100. –î–ª—è –ø–µ—Ä–≤–æ–≥–æ –≥–æ–¥–∞ = null
  * –í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å = –í—ã—Ä—É—á–∫–∞ - –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂
  * –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–∞–ª–æ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏, % = (–í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å / –í—ã—Ä—É—á–∫–∞) * 100
  * –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å = –í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å - –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ —Ä–∞—Å—Ö–æ–¥—ã - –£–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–µ —Ä–∞—Å—Ö–æ–¥—ã
  * –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, % = (–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å / –í—ã—Ä—É—á–∫–∞) * 100
  * –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏, % = (–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –í—ã—Ä—É—á–∫–∞) * 100

**–ò–∑ –æ—Ç—á–µ—Ç–∞ –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏ (–±–∞–ª–∞–Ω—Å):**
  * –ê–∫—Ç–∏–≤—ã –∏—Ç–æ–≥–æ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –ó–∞–ø–∞—Å—ã - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∑–∞–ø–∞—Å–æ–≤, —Ä–∞–∑ = –í—ã—Ä—É—á–∫–∞ / –°—Ä–µ–¥–Ω–∏–µ –∑–∞–ø–∞—Å—ã (—Å—Ä–µ–¥–Ω–∏–µ = (–ó–∞–ø–∞—Å—ã –Ω–∞ –Ω–∞—á–∞–ª–æ + –ó–∞–ø–∞—Å—ã –Ω–∞ –∫–æ–Ω–µ—Ü) / 2)
  * –î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ = –í—ã—Ä—É—á–∫–∞ / –°—Ä–µ–¥–Ω—è—è –¥–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å
  * –ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ = –í—ã—Ä—É—á–∫–∞ / –°—Ä–µ–¥–Ω—è—è –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å
  * –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª = –û–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã - –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
  * –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞, % = (–û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞) * 100
  * –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ = (–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ + –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞) - (–î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ + –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è)
  * –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å, x = –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å

**–ò–∑ –æ—Ç—á–µ—Ç–∞ –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤:**
  * –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
  * –ò—Ç–æ–≥–æ–≤—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥ = –°–∞–ª—å–¥–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π + –°–∞–ª—å–¥–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π + –°–∞–ª—å–¥–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π
  * –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ - –∏–∑–≤–ª–µ–∫–∞–π –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  * –†–∞–∑–Ω–∏—Ü–∞: –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ - –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –û–° = –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ - –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è analysis.key_metrics:**
  * ROE (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–ø–∏—Ç–∞–ª–∞) = –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã
  * ROA (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–æ–≤) = –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –ê–∫—Ç–∏–≤—ã –∏—Ç–æ–≥–æ
  * Current Ratio (—Ç–µ–∫—É—â–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å) = –û–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã / –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
  * Quick Ratio (–±—ã—Å—Ç—Ä–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å) = (–û–±–æ—Ä–æ—Ç–Ω—ã–µ –∞–∫—Ç–∏–≤—ã - –ó–∞–ø–∞—Å—ã) / –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
  * Debt/Equity (–¥–æ–ª–≥/–∫–∞–ø–∏—Ç–∞–ª) = (–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ + –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞) / –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã

- –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Å—Å–∏–≤ years –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥–æ–¥–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
- –î–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –í–ï–†–ù–ò –¢–û–õ–¨–ö–û JSON, –±–µ–∑ markdown –±–ª–æ–∫–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ –≤–æ–∫—Ä—É–≥

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –∫–∞–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫—Ä—É–ø–Ω–æ–≥–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–æ–Ω–¥–∞."""

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini
        import google.generativeai as genai
        
        # –°–æ–∑–¥–∞–µ–º —á–∞—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
        parts = [
            prompt,
            {
                "mime_type": "application/pdf",
                "data": pdf_base64
            }
        ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = model.generate_content(parts)
        
        # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        response_text = response.text.strip()
        
        # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()
        
        # –ü–∞—Ä—Å–∏–º JSON
        data = json.loads(response_text)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result["success"] = True
        result["report_type"] = data.get("report_type")
        result["report_year"] = data.get("report_year")
        result["company_info"] = data.get("company_info", {})
        result["multi_year_data"] = data.get("multi_year_data")
        result["analysis"] = data.get("analysis")
        result["text"] = ""  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        
    except json.JSONDecodeError as e:
        result["error"] = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç AI: {str(e)}"
        result["raw_response"] = response_text if 'response_text' in locals() else None
    except Exception as e:
        result["error"] = f"–û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
    
    return result

def download_and_parse_boh(state: AgentState) -> AgentState:
    inn = normalize_inn(state["inn"])
    out_dir = f"reports_{inn}"
    os.makedirs(out_dir, exist_ok=True)
    
    st.info("üìä –ó–∞–≥—Ä—É–∂–∞—é –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å...")
    time.sleep(20)
    
    for attempt in range(3):
        try:
            resp = requests.get(f"{BASE_BOH_URL}ls.php", params={"inn": inn}, headers=HEADERS, timeout=15)
            resp.raise_for_status()
            break
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:
                wait = 60 * (attempt + 1)
                st.warning(f"‚ö†Ô∏è 429. –ñ–¥–µ–º {wait} —Å–µ–∫...")
                time.sleep(wait)
                if attempt == 2:
                    return {"boh_parsed": [{"error": "429"}]}
            else:
                return {"boh_parsed": [{"error": f"HTTP {e.response.status_code}"}]}

    soup = BeautifulSoup(resp.text, "html.parser")
    links = soup.find_all('a', string='–°–∫–∞—á–∞—Ç—å')
    
    if not links:
        st.warning("‚ö†Ô∏è –§–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return {"boh_parsed": []}
    
    # –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú –í–°–ï –§–ê–ô–õ–´ –ë–ï–ó –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô!
    total_files = len(links)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
    xml_count = sum(1 for link in links if '.xml' in link.get('href', '').lower())
    pdf_count = total_files - xml_count
    
    st.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏: {total_files} (XML: {xml_count}, PDF: {pdf_count})")
    st.info(f"üì• –°–∫–∞—á–∏–≤–∞—é –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –í–°–ï —Ñ–∞–π–ª—ã...")
    
    parsed_files = []
    
    progress = st.progress(0)
    
    for idx, link in enumerate(links, 1):
        href = link.get("href")
        if not href:
            continue

        if idx > 1:
            time.sleep(20)
        
        url = urljoin(BASE_BOH_URL, href)
        is_xml = '.xml' in href.lower()
        ext = '.xml' if is_xml else '.pdf'
        filename = f"report_{inn}_{idx}{ext}"
        path = os.path.join(out_dir, filename)
        
        st.text(f"üì• {filename}")
        
        try:
            r = requests.get(url, headers=HEADERS, timeout=30, stream=True)
            r.raise_for_status()
            
            with open(path, "wb") as f:
                for chunk in r.iter_content(8192):
                    if chunk:
                        f.write(chunk)
            
            if is_xml or path.endswith('.xml'):
                # XML - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –ø–∞—Ä—Å–µ—Ä
                parsed = extract_from_xml(path)
            else:
                # PDF - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–ø—Ä—è–º—É—é –≤ Gemini –∫–∞–∫ –∏–Ω–≤–µ—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫
                st.info(f"ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é {filename} —Å –ø–æ–º–æ—â—å—é AI...")
                parsed = analyze_pdf_with_gemini(path, filename)
            
            parsed_files.append(parsed)
            
            if parsed.get("success"):
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç AI-–∞–Ω–∞–ª–∏–∑–∞
                if parsed.get("analysis"):
                    analysis = parsed["analysis"]
                    rating = analysis.get("investment_rating", "N/A")
                    health = analysis.get("financial_health", "N/A")
                    recommendation = analysis.get("investment_recommendation", "")
                    
                    # –≠–º–æ–¥–∑–∏ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
                    rating_emoji = {
                        "A": "üü¢", "A-": "üü¢", 
                        "B+": "üü°", "B": "üü°", "B-": "üü°",
                        "C": "üî¥", "C-": "üî¥"
                    }.get(rating, "‚ö™")
                    
                    st.success(f"‚úÖ {filename} {rating_emoji} –†–µ–π—Ç–∏–Ω–≥: {rating} | –°–æ—Å—Ç–æ—è–Ω–∏–µ: {health}")
                    if recommendation:
                        st.info(f"   üí° {recommendation}")
                else:
                    # –î–ª—è XML —Ñ–∞–π–ª–æ–≤ - —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                    char_count = len(parsed.get("text", ""))
                    info_parts = [f"{char_count} —Å–∏–º–≤–æ–ª–æ–≤"]
                    
                    if parsed.get("report_year"):
                        info_parts.append(f"–ì–æ–¥: {parsed['report_year']}")
                    
                    if parsed.get("structured_data"):
                        sd = parsed["structured_data"]
                        if sd.get("balance"):
                            info_parts.append("–ë–∞–ª–∞–Ω—Å ‚úì")
                        if sd.get("financial_results"):
                            info_parts.append("Fin–†–µ–∑ ‚úì")
                    
                    st.success(f"‚úÖ {filename} " + " | ".join(info_parts))
            else:
                error_msg = parsed.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')
                st.warning(f"‚ö†Ô∏è {filename}: {error_msg}")
                
        except Exception as e:
            parsed_files.append({"filename": filename, "error": str(e)})
            st.error(f"‚ùå {filename}: {str(e)}")
        
        progress.progress(idx / len(links))
    
    progress.empty()
    
    # –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    successful = [f for f in parsed_files if f.get("success")]
    
    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º
    xml_files = [f for f in parsed_files if f.get("filename", "").endswith('.xml')]
    pdf_files = [f for f in parsed_files if f.get("filename", "").endswith('.pdf')]
    
    xml_success = [f for f in xml_files if f.get("success")]
    pdf_success = [f for f in pdf_files if f.get("success")]
    
    st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful)}/{len(parsed_files)} —Ñ–∞–π–ª–æ–≤")
    st.info(f"   üìÑ XML: {len(xml_success)}/{len(xml_files)} | üìã PDF: {len(pdf_success)}/{len(pdf_files)}")
    
    return {"boh_parsed": parsed_files}

def get_case_pdf_url(case_number: str) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç URL PDF —Ñ–∞–π–ª–∞ —Ä–µ—à–µ–Ω–∏—è –ø–æ –¥–µ–ª—É —á–µ—Ä–µ–∑ API
    """
    if not case_number:
        return None
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–µ–ª–∞
        details_url = f"https://parser-api.com/parser/arbitr_api/details_by_number?key={ARBITRATION_API_KEY}&CaseNumber={case_number}"
        response = requests.get(details_url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if data.get("Success") != 1:
            return None
        
        cases = data.get("Cases", [])
        if not cases:
            return None
        
        case_data = cases[0]
        
        # –ò—â–µ–º PDF —Ñ–∞–π–ª –≤ –∏–Ω—Å—Ç–∞–Ω—Ü–∏—è—Ö
        instances = case_data.get("CaseInstances", [])
        for instance in instances:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –∏–Ω—Å—Ç–∞–Ω—Ü–∏–∏
            file_info = instance.get("File")
            if file_info and file_info.get("URL"):
                return file_info["URL"]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏—è (–∏—â–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ)
            events = instance.get("InstanceEvents", [])
            for event in events:
                if event.get("FinishEvent") == 1:  # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
                    pdf_url = event.get("File")
                    if pdf_url:
                        return pdf_url
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ, –±–µ—Ä–µ–º –ª—é–±–æ–π PDF –∏–∑ —Å–æ–±—ã—Ç–∏–π
        for instance in instances:
            events = instance.get("InstanceEvents", [])
            for event in events:
                pdf_url = event.get("File")
                if pdf_url:
                    return pdf_url
        
        return None
        
    except Exception as e:
        return None

def get_case_summary_from_api(case_number: str) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ–ª–µ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –°–£–¢–ò –ö–û–ù–§–õ–ò–ö–¢–ê
    –ù–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –ø–æ–ª–µ–π API (–Ω–µ –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö!)
    """
    if not case_number:
        return "–ù–æ–º–µ—Ä –¥–µ–ª–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –î–ï–¢–ê–õ–¨–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ–ª–µ
        details_url = f"https://parser-api.com/parser/arbitr_api/details_by_number?key={ARBITRATION_API_KEY}&CaseNumber={case_number}"
        response = requests.get(details_url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if data.get("Success") != 1:
            return "–î–µ—Ç–∞–ª–∏ –¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
        
        # –í –æ—Ç–≤–µ—Ç–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∞—Å—Å–∏–≤ Cases
        cases = data.get("Cases", [])
        if not cases:
            return "–î–µ—Ç–∞–ª–∏ –¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
        
        case_data = cases[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –¥–µ–ª–æ
        
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –†–ï–ê–õ–¨–ù–û —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π
        info_parts = []
        
        # 1. –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–µ–ª–∞ (State)
        state = case_data.get("State", "")
        if state:
            info_parts.append(f"–°–æ—Å—Ç–æ—è–Ω–∏–µ: {state}")
        
        # 2. –°—É–º–º–∞ –∏—Å–∫–∞ - –∏—â–µ–º –≤ —Å–æ–±—ã—Ç–∏—è—Ö (ClaimSum)
        claim_sum = None
        instances = case_data.get("CaseInstances", [])
        for instance in instances:
            events = instance.get("InstanceEvents", [])
            for event in events:
                if event.get("ClaimSum"):
                    claim_sum = event["ClaimSum"]
                    break
            if claim_sum:
                break
        
        if claim_sum:
            info_parts.append(f"–°—É–º–º–∞ –∏—Å–∫–∞: {claim_sum:,.0f} —Ä—É–±.")
        
        # 3. –¢–∏–ø —Ä–µ—à–µ–Ω–∏—è - –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–±—ã—Ç–∏—è
        decision_info = None
        for instance in instances:
            events = instance.get("InstanceEvents", [])
            if events:
                # –ò—â–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ (—Ä–µ—à–µ–Ω–∏–µ)
                for event in events:
                    if event.get("FinishEvent") == 1:
                        event_type = event.get("EventTypeName", "")
                        content_type = event.get("EventContentTypeName", "")
                        if content_type:
                            decision_info = content_type
                        elif event_type:
                            decision_info = event_type
                        break
        
        if decision_info:
            info_parts.append(f"–†–µ—à–µ–Ω–∏–µ: {decision_info}")
        
        # 4. –¢–∏–ø –¥–µ–ª–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        case_type = case_data.get("CaseType", "")
        type_desc = {
            "–ê": "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Ä",
            "–ë": "–±–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–æ",
            "–ì": "–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π —Å–ø–æ—Ä"
        }.get(case_type, "—Å–ø–æ—Ä")
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–±—Ä–∞–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if not info_parts:
            # –ü—ã—Ç–∞–µ–º—Å—è —Ö–æ—Ç—è –±—ã —É–∫–∞–∑–∞—Ç—å —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
            plaintiffs = case_data.get("Plaintiffs", [])
            respondents = case_data.get("Respondents", [])
            
            if plaintiffs and respondents:
                p_name = plaintiffs[0].get("Name", "")[:30] if plaintiffs else ""
                r_name = respondents[0].get("Name", "")[:30] if respondents else ""
                
                if p_name and r_name:
                    return f"{type_desc.capitalize()}: {p_name} vs {r_name}"
            
            return "–î–µ—Ç–∞–ª–∏ –¥–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –≤ API"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è AI
        full_context = "\n".join(info_parts)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ AI –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ
        prompt = f"""–¢—ã - —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –°–æ–∑–¥–∞–π –ö–†–ê–¢–ö–û–ï –æ–ø–∏—Å–∞–Ω–∏–µ (–¥–æ 15 —Å–ª–æ–≤) —Å—É—Ç–∏ —Å—É–¥–µ–±–Ω–æ–≥–æ –¥–µ–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –î–û–°–¢–£–ü–ù–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:

{full_context}

–¢–∏–ø –¥–µ–ª–∞: {type_desc}

–í–ê–ñ–ù–û:
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
- –£–∫–∞–∂–∏ —Å—É–º–º—É –µ—Å–ª–∏ –µ—Å—Ç—å
- –£–∫–∞–∂–∏ —Å—É—Ç—å —Ä–µ—à–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
- –ú–∞–∫—Å–∏–º—É–º 15 —Å–ª–æ–≤!

–ü–†–ò–ú–ï–†–´ –•–û–†–û–®–ò–• –û–ü–ò–°–ê–ù–ò–ô:
‚ùå –ü–õ–û–•–û: "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Ä"
‚úÖ –•–û–†–û–®–û: "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Ä, –∏—Å–∫ 500 —Ç—ã—Å. —Ä—É–±., –∏—Å–∫ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω"

‚ùå –ü–õ–û–•–û: "–ë–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–æ"
‚úÖ –•–û–†–û–®–û: "–ë–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–æ, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–æ—Ä–æ–≤ 2 –º–ª–Ω —Ä—É–±."

–¢–≤–æ–µ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–¥–æ 15 —Å–ª–æ–≤):"""

        response_ai = model.generate_content(prompt)
        summary = response_ai.text.strip()
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        summary = summary.replace('"', '').replace("'", "").replace('‚úÖ', '').replace('‚ùå', '').strip()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(summary) > 150:
            summary = summary[:147] + "..."
        
        return summary
        
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π: {str(e)[:30]}"

def fetch_arbitration_data(state: AgentState) -> AgentState:
    inn = normalize_inn(state["inn"])
    
    st.info("‚öñÔ∏è –ó–∞–≥—Ä—É–∂–∞—é —Å—É–¥–µ–±–Ω—ã–µ –¥–µ–ª–∞...")
    
    result = {
        "plaintiff_cases": [],
        "respondent_cases": [],
        "third_party_cases": [],
        "total": 0,
        "plaintiff_total": 0,
        "respondent_total": 0,
        "third_party_total": 0
    }
    
    try:
        # –¢–∏–ø—ã –¥–µ–ª –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏
        CASE_TYPES = {
            "–ê": "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ",
            "–ë": "–ë–∞–Ω–∫—Ä–æ—Ç–Ω–æ–µ",
            "–ì": "–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ"
        }
        
        # 1. –ó–ê–ì–†–£–ñ–ê–ï–ú –î–ï–õ–ê –ì–î–ï –ö–û–ú–ü–ê–ù–ò–Ø - –ò–°–¢–ï–¶
        st.info("üìã –ó–∞–≥—Ä—É–∂–∞—é –¥–µ–ª–∞ (–∏—Å—Ç–µ—Ü)...")
        try:
            response_plaintiff = requests.get(
                ARBITRATION_API_URL, 
                params={'key': ARBITRATION_API_KEY, 'Inn': inn, 'InnType': 'Plaintiff'}
            )
            response_plaintiff.raise_for_status()
            data_plaintiff = response_plaintiff.json()
            
            if data_plaintiff.get("Success") == 1:
                cases_plaintiff = data_plaintiff.get("Cases", [])
                
                for idx, case in enumerate(cases_plaintiff):
                    case_number = safe_get(case, "CaseNumber")
                    case_type = safe_get(case, "CaseType")
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                    plaintiffs_list = []
                    for p in (case.get("Plaintiffs") or []):
                        if isinstance(p, dict):
                            plaintiffs_list.append({
                                "name": p.get("Name"),
                                "inn": p.get("Inn"),
                                "address": p.get("Address")
                            })
                    
                    respondents_list = []
                    for r in (case.get("Respondents") or []):
                        if isinstance(r, dict):
                            respondents_list.append({
                                "name": r.get("Name"),
                                "inn": r.get("Inn"),
                                "address": r.get("Address")
                            })
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–µ–ª–∞ (–¥–ª—è –í–°–ï–• –¥–µ–ª!)
                    case_summary = "..."
                    pdf_url = None
                    if case_number:
                        st.text(f"   üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–µ–ª–æ {case_number}...")
                        case_summary = get_case_summary_from_api(case_number)
                        # –ü–æ–ª—É—á–∞–µ–º PDF URL
                        pdf_url = get_case_pdf_url(case_number)
                    
                    parsed_case = {
                        "number": case_number,
                        "case_id": safe_get(case, "CaseId"),
                        "case_type": CASE_TYPES.get(case_type, case_type),
                        "case_type_code": case_type,
                        "court": safe_get(case, "Court", "Name") if isinstance(safe_get(case, "Court"), dict) else safe_get(case, "Court"),
                        "start_date": safe_get(case, "StartDate"),
                        "plaintiffs": plaintiffs_list,
                        "respondents": respondents_list,
                        "summary": case_summary,
                        "pdf_url": pdf_url,
                        "details_url": f"https://parser-api.com/parser/arbitr_api/details_by_number?key={ARBITRATION_API_KEY}&CaseNumber={case_number}" if case_number else None
                    }
                    
                    result["plaintiff_cases"].append(parsed_case)
                
                result["plaintiff_total"] = len(cases_plaintiff)
                st.success(f"‚úÖ –ò—Å—Ç–µ—Ü: {len(cases_plaintiff)} –¥–µ–ª")
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ–ª (–∏—Å—Ç–µ—Ü): {str(e)}")
        
        # 2. –ó–ê–ì–†–£–ñ–ê–ï–ú –î–ï–õ–ê –ì–î–ï –ö–û–ú–ü–ê–ù–ò–Ø - –û–¢–í–ï–¢–ß–ò–ö
        st.info("üìã –ó–∞–≥—Ä—É–∂–∞—é –¥–µ–ª–∞ (–æ—Ç–≤–µ—Ç—á–∏–∫)...")
        try:
            response_respondent = requests.get(
                ARBITRATION_API_URL, 
                params={'key': ARBITRATION_API_KEY, 'Inn': inn, 'InnType': 'Respondent'}
            )
            response_respondent.raise_for_status()
            data_respondent = response_respondent.json()
            
            if data_respondent.get("Success") == 1:
                cases_respondent = data_respondent.get("Cases", [])
                
                for idx, case in enumerate(cases_respondent):
                    case_number = safe_get(case, "CaseNumber")
                    case_type = safe_get(case, "CaseType")
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                    plaintiffs_list = []
                    for p in (case.get("Plaintiffs") or []):
                        if isinstance(p, dict):
                            plaintiffs_list.append({
                                "name": p.get("Name"),
                                "inn": p.get("Inn"),
                                "address": p.get("Address")
                            })
                    
                    respondents_list = []
                    for r in (case.get("Respondents") or []):
                        if isinstance(r, dict):
                            respondents_list.append({
                                "name": r.get("Name"),
                                "inn": r.get("Inn"),
                                "address": r.get("Address")
                            })
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–µ–ª–∞ (–¥–ª—è –í–°–ï–• –¥–µ–ª!)
                    case_summary = "..."
                    pdf_url = None
                    if case_number:
                        st.text(f"   üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–µ–ª–æ {case_number}...")
                        case_summary = get_case_summary_from_api(case_number)
                        # –ü–æ–ª—É—á–∞–µ–º PDF URL
                        pdf_url = get_case_pdf_url(case_number)
                    
                    parsed_case = {
                        "number": case_number,
                        "case_id": safe_get(case, "CaseId"),
                        "case_type": CASE_TYPES.get(case_type, case_type),
                        "case_type_code": case_type,
                        "court": safe_get(case, "Court", "Name") if isinstance(safe_get(case, "Court"), dict) else safe_get(case, "Court"),
                        "start_date": safe_get(case, "StartDate"),
                        "plaintiffs": plaintiffs_list,
                        "respondents": respondents_list,
                        "summary": case_summary,
                        "pdf_url": pdf_url,
                        "details_url": f"https://parser-api.com/parser/arbitr_api/details_by_number?key={ARBITRATION_API_KEY}&CaseNumber={case_number}" if case_number else None
                    }
                    
                    result["respondent_cases"].append(parsed_case)
                
                result["respondent_total"] = len(cases_respondent)
                st.success(f"‚úÖ –û—Ç–≤–µ—Ç—á–∏–∫: {len(cases_respondent)} –¥–µ–ª")
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ–ª (–æ—Ç–≤–µ—Ç—á–∏–∫): {str(e)}")
        
        # 3. –ó–ê–ì–†–£–ñ–ê–ï–ú –î–ï–õ–ê –ì–î–ï –ö–û–ú–ü–ê–ù–ò–Ø - –¢–†–ï–¢–¨–ï –õ–ò–¶–û
        st.info("üìã –ó–∞–≥—Ä—É–∂–∞—é –¥–µ–ª–∞ (—Ç—Ä–µ—Ç—å–µ –ª–∏—Ü–æ)...")
        try:
            response_third = requests.get(
                ARBITRATION_API_URL, 
                params={'key': ARBITRATION_API_KEY, 'Inn': inn, 'InnType': 'Third'}
            )
            response_third.raise_for_status()
            data_third = response_third.json()
            
            if data_third.get("Success") == 1:
                cases_third = data_third.get("Cases", [])
                
                for idx, case in enumerate(cases_third):
                    case_number = safe_get(case, "CaseNumber")
                    case_type = safe_get(case, "CaseType")
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
                    plaintiffs_list = []
                    for p in (case.get("Plaintiffs") or []):
                        if isinstance(p, dict):
                            plaintiffs_list.append({
                                "name": p.get("Name"),
                                "inn": p.get("Inn")
                            })
                    
                    respondents_list = []
                    for r in (case.get("Respondents") or []):
                        if isinstance(r, dict):
                            respondents_list.append({
                                "name": r.get("Name"),
                                "inn": r.get("Inn")
                            })
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–µ–ª–∞ (–¥–ª—è –í–°–ï–• –¥–µ–ª!)
                    case_summary = "..."
                    pdf_url = None
                    if case_number:
                        st.text(f"   üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–µ–ª–æ {case_number}...")
                        case_summary = get_case_summary_from_api(case_number)
                        # –ü–æ–ª—É—á–∞–µ–º PDF URL
                        pdf_url = get_case_pdf_url(case_number)
                    
                    parsed_case = {
                        "number": case_number,
                        "case_id": safe_get(case, "CaseId"),
                        "case_type": CASE_TYPES.get(case_type, case_type),
                        "case_type_code": case_type,
                        "court": safe_get(case, "Court", "Name") if isinstance(safe_get(case, "Court"), dict) else safe_get(case, "Court"),
                        "start_date": safe_get(case, "StartDate"),
                        "plaintiffs": plaintiffs_list,
                        "respondents": respondents_list,
                        "summary": case_summary,
                        "pdf_url": pdf_url,
                        "details_url": f"https://parser-api.com/parser/arbitr_api/details_by_number?key={ARBITRATION_API_KEY}&CaseNumber={case_number}" if case_number else None
                    }
                    
                    result["third_party_cases"].append(parsed_case)
                
                result["third_party_total"] = len(cases_third)
                if len(cases_third) > 0:
                    st.success(f"‚úÖ –¢—Ä–µ—Ç—å–µ –ª–∏—Ü–æ: {len(cases_third)} –¥–µ–ª")
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ–ª (—Ç—Ä–µ—Ç—å–µ –ª–∏—Ü–æ): {str(e)}")
        
        # –ò–¢–û–ì–û
        result["total"] = result["plaintiff_total"] + result["respondent_total"] + result["third_party_total"]
        
        st.success(f"‚úÖ –ò–¢–û–ì–û: {result['total']} –¥–µ–ª (–∏—Å—Ç–µ—Ü: {result['plaintiff_total']}, –æ—Ç–≤–µ—Ç—á–∏–∫: {result['respondent_total']}, —Ç—Ä–µ—Ç—å–µ –ª–∏—Ü–æ: {result['third_party_total']})")
        
        return {"courts_parsed": result}
        
    except Exception as e:
        st.error(f"‚ùå –°—É–¥—ã: {str(e)}")
        return {"courts_parsed": {"error": str(e), "total": 0}}

def fetch_media_mentions(state: AgentState) -> AgentState:
    """–ò—â–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –°–ú–ò —á–µ—Ä–µ–∑ Exa API"""
    
    if not EXA_AVAILABLE:
        st.warning("‚ö†Ô∏è Exa API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install exa_py")
        return {"media_mentions": []}
    
    egrul = state.get("egrul_parsed", {})
    company_name = egrul.get("short_name") or egrul.get("full_name", "")
    
    if not company_name:
        return {"media_mentions": []}
    
    st.info(f"üì∞ –ò—â—É —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –°–ú–ò...")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Exa –∫–ª–∏–µ–Ω—Ç
        exa = Exa(api_key=EXA_API_KEY)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = f"—Å—Ç–∞—Ç—å—è –Ω–æ–≤–æ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ {company_name}"
        
        # –ü–æ–∏—Å–∫ —Å –ø–æ–ª—É—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        response = exa.search_and_contents(
            query,
            num_results=10,
            use_autoprompt=True,
            text={"max_characters": 500},  # –ö—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
            highlights={"num_sentences": 3,  # –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                       "highlights_per_url": 3}
        )
        
        mentions = []
        for result in response.results:
            mention = {
                "title": result.title or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è",
                "url": result.url,
                "published_date": result.published_date if hasattr(result, 'published_date') else None,
                "author": result.author if hasattr(result, 'author') else None,
                "text": result.text if hasattr(result, 'text') else None,
                "highlights": result.highlights if hasattr(result, 'highlights') else []
            }
            mentions.append(mention)
        
        st.success(f"‚úÖ –°–ú–ò: –Ω–∞–π–¥–µ–Ω–æ {len(mentions)} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
        return {"media_mentions": mentions}
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –°–ú–ò: {str(e)}")
        return {"media_mentions": []}

# ==================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê ====================
def merge_and_analyze(state: AgentState) -> AgentState:
    egrul = state["egrul_parsed"]
    fin = state["fin_parsed"]
    boh = state["boh_parsed"]
    courts = state["courts_parsed"]
    related = state["related_companies"]
    media = state.get("media_mentions", [])
    
    # –°—Ç—Ä–æ–∏–º –¥–∏–∞–≥—Ä–∞–º–º—É —Å–µ—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–π
    network_diagram = build_company_network_diagram(egrul.get("basic_info", {}), related)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å —Ñ–∞–π–ª–∞–º–∏ –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
    boh_section = []
    for i, f in enumerate(boh):
        status = '‚úÖ –£—Å–ø–µ—à–Ω–æ' if f.get('success') else f'‚ùå {f.get("error", "–û—à–∏–±–∫–∞")}'
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å AI-–∞–Ω–∞–ª–∏–∑ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if f.get('analysis'):
            multi_data = f.get('multi_year_data', {})
            analysis = f['analysis']
            
            # –£–≤–µ–ª–∏—á–µ–Ω—ã –ª–∏–º–∏—Ç—ã –≤ 10 —Ä–∞–∑ —á—Ç–æ–±—ã Gemini –ø–æ–ª—É—á–∞–ª –í–°–ï –¥–∞–Ω–Ω—ã–µ!
            data_preview = json.dumps(multi_data, ensure_ascii=False, indent=2)[:20000]
            analysis_preview = json.dumps(analysis, ensure_ascii=False, indent=2)[:15000]
            
            boh_section.append(f"""### {i+1}. {f['filename']} - {status} ü§ñ AI-–ê–ù–ê–õ–ò–ó
**–¢–∏–ø:** {f.get('report_type', 'N/A')}
**–ì–æ–¥ –æ—Ç—á–µ—Ç–∞:** {f.get('report_year', 'N/A')}
**–ö–æ–º–ø–∞–Ω–∏—è:** {f.get('company_info', {}).get('name', 'N/A')} (–ò–ù–ù: {f.get('company_info', {}).get('inn', 'N/A')})
**–ì–æ–¥—ã –≤ –¥–∞–Ω–Ω—ã—Ö:** {', '.join(multi_data.get('years', []))}

**–°–í–û–î–ù–´–ï –î–ê–ù–ù–´–ï (–¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º):**
```json
{data_preview}
```

**AI-–ê–ù–ê–õ–ò–ó –ò–ù–í–ï–°–¢-–ê–ù–ê–õ–ò–¢–ò–ö–ê:**
```json
{analysis_preview}
```

**–ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã:**
- **–§–∏–Ω–∞–Ω—Å–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:** {analysis.get('financial_health', 'N/A')}
- **–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥:** {analysis.get('investment_rating', 'N/A')}
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {analysis.get('investment_recommendation', 'N/A')}
- **–†–µ–∑—é–º–µ:** {analysis.get('summary', 'N/A')}
""")
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –°–í–û–î–ù–´–ï –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º –µ—Å–ª–∏ –µ—Å—Ç—å (–¥–ª—è XML)
        elif f.get('multi_year_data'):
            multi_data = f['multi_year_data']
            # –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç –≤ 10 —Ä–∞–∑
            data_preview = json.dumps(multi_data, ensure_ascii=False, indent=2)[:20000]
            boh_section.append(f"""### {i+1}. {f['filename']} - {status}
**–¢–∏–ø:** {f.get('report_type', 'N/A')}
**–ì–æ–¥ –æ—Ç—á–µ—Ç–∞:** {f.get('report_year', 'N/A')}
**–ì–æ–¥—ã –≤ —Ç–∞–±–ª–∏—Ü–µ:** {', '.join(multi_data.get('years', []))}

**–°–í–û–î–ù–´–ï –î–ê–ù–ù–´–ï (–¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º):**
```json
{data_preview}
```""")
        elif f.get('structured_data'):
            # –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç –≤ 10 —Ä–∞–∑
            data_preview = json.dumps(f['structured_data'], ensure_ascii=False, indent=2)[:15000]
            boh_section.append(f"### {i+1}. {f['filename']} - {status}\n**–¢–∏–ø:** {f.get('report_type', 'N/A')}\n**–ì–æ–¥:** {f.get('report_year', 'N/A')}\n```json\n{data_preview}\n```")
        else:
            # –£–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç –≤ 10 —Ä–∞–∑
            text_preview = f.get('text', '')[:8000]
            boh_section.append(f"### {i+1}. {f['filename']} - {status}\n```\n{text_preview}\n```")
    
    boh_text = "\n\n".join(boh_section)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ë–ï–ó –ó–ê–ì–õ–£–®–ï–ö
    data_summary = f"""
# –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï (–ë–ï–ó –ó–ê–ì–õ–£–®–ï–ö)

## –ï–ì–†–Æ–õ - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:
–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {egrul.get('raw_json_structure', [])}

## –ï–ì–†–Æ–õ - –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
```json
{json.dumps(egrul.get('all_fields', {}), ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –ê–¥—Ä–µ—Å:
```json
{json.dumps(egrul.get('address', {}), ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ ({len(egrul.get('directors', []))} —á–µ–ª.):
```json
{json.dumps(egrul.get('directors', []), ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –£—á—Ä–µ–¥–∏—Ç–µ–ª–∏ ({len(egrul.get('founders', []))} —á–µ–ª.):
```json
{json.dumps(egrul.get('founders', []), ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ ({len(related)} —à—Ç.):
```json
{json.dumps(related, ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –û–ö–í–≠–î:
```json
{json.dumps(egrul.get('okved', {}), ensure_ascii=False, indent=2)}
```

## –ï–ì–†–Æ–õ - –£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª:
{egrul.get('capital') if egrul.get('capital') is not None else '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ JSON'}

---

## –§–ò–ù–ê–ù–°–´ - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:
–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {fin.get('raw_json_structure', [])}

## –§–ò–ù–ê–ù–°–´ - –î–æ—Ö–æ–¥—ã/—Ä–∞—Å—Ö–æ–¥—ã ({len(fin.get('income_expenses', []))} –∑–∞–ø–∏—Å–µ–π):
```json
{json.dumps(fin.get('income_expenses', []), ensure_ascii=False, indent=2)}
```

## –§–ò–ù–ê–ù–°–´ - –ù–∞–ª–æ–≥–∏ ({len(fin.get('taxes', []))} –∑–∞–ø–∏—Å–µ–π):
```json
{json.dumps(fin.get('taxes', []), ensure_ascii=False, indent=2)}
```

## –§–ò–ù–ê–ù–°–´ - –ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å ({len(fin.get('employees', []))} –∑–∞–ø–∏—Å–µ–π):
```json
{json.dumps(fin.get('employees', []), ensure_ascii=False, indent=2)}
```

## –§–ò–ù–ê–ù–°–´ - –ù–∞–ª–æ–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã:
{fin.get('tax_systems') if fin.get('tax_systems') else '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}

## –§–ò–ù–ê–ù–°–´ - –†–∞–∑–º–µ—Ä –∫–æ–º–ø–∞–Ω–∏–∏:
{fin.get('company_size') if fin.get('company_size') else '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}

## –§–ò–ù–ê–ù–°–´ - –ì–æ—Å–ø–æ–¥–¥–µ—Ä–∂–∫–∞ ({len(fin.get('support', []))} –∑–∞–ø–∏—Å–µ–π):
```json
{json.dumps(fin.get('support', []), ensure_ascii=False, indent=2)}
```

---

## –ë–£–•–û–¢–ß–ï–¢–ù–û–°–¢–¨ - –§–∞–π–ª–æ–≤: {len(boh)}

{boh_text}

---

## –°–£–î–´ - –í—Å–µ–≥–æ –¥–µ–ª: {courts.get('total', 0)}

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
- –ò—Å—Ç–µ—Ü: {courts.get('plaintiff_total', 0)} –¥–µ–ª
- –û—Ç–≤–µ—Ç—á–∏–∫: {courts.get('respondent_total', 0)} –¥–µ–ª
- –¢—Ä–µ—Ç—å–µ –ª–∏—Ü–æ: {courts.get('third_party_total', 0)} –¥–µ–ª

### –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –ò–°–¢–ï–¶ ({courts.get('plaintiff_total', 0)} –¥–µ–ª):
```json
{json.dumps(courts.get('plaintiff_cases', []), ensure_ascii=False, indent=2)}
```

### –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –û–¢–í–ï–¢–ß–ò–ö ({courts.get('respondent_total', 0)} –¥–µ–ª):
```json
{json.dumps(courts.get('respondent_cases', []), ensure_ascii=False, indent=2)}
```

### –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –¢–†–ï–¢–¨–ï –õ–ò–¶–û ({courts.get('third_party_total', 0)} –¥–µ–ª):
```json
{json.dumps(courts.get('third_party_cases', []), ensure_ascii=False, indent=2)}
```

---

## üì∞ –£–ü–û–ú–ò–ù–ê–ù–ò–Ø –í –°–ú–ò

**–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π:** {len(media)}

{json.dumps(media, ensure_ascii=False, indent=2) if media else "[]"}
"""

    prompt = f"""
–¢—ã ‚Äî —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤—â–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ø–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ —á–∏—Ç–∞–µ–º—ã–π markdown –æ—Ç—á–µ—Ç.

**–ó–ê–ü–†–ï–©–ï–ù–û:**
- –ü—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
- –î–æ–±–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç —Å–µ–±—è
- –ü–∏—Å–∞—Ç—å "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" –µ—Å–ª–∏ –≤ JSON –µ—Å—Ç—å null –∏–ª–∏ –ø—É—Å—Ç–æ - –ø–∏—à–∏ "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ API"

**–†–ê–ó–†–ï–®–ï–ù–û:**
- –ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ —Ç–∞–±–ª–∏—Ü—ã
- –î–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –ù–ê –û–°–ù–û–í–ï –¶–ò–§–† –∏–∑ –¥–∞–Ω–Ω—ã—Ö
- –°—Ç—Ä–æ–∏—Ç—å –¥–∏–∞–≥—Ä–∞–º–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å —É—á—Ä–µ–¥–∏—Ç–µ–ª–∏

# –°–æ–∑–¥–∞–π –æ—Ç—á–µ—Ç –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:

## üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–ú–ü–ê–ù–ò–ò

### 1. üè¢ –û–°–ù–û–í–ù–´–ï –°–í–ï–î–ï–ù–ò–Ø
–ü—Ä–µ–æ–±—Ä–∞–∑—É–π `all_fields` –≤ —Ç–∞–±–ª–∏—Ü—É:
| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|

–ï—Å–ª–∏ –ø–æ–ª–µ = null ‚Üí "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ API"

### 2. üìç –Æ–†–ò–î–ò–ß–ï–°–ö–ò–ô –ê–î–†–ï–°
–ï—Å–ª–∏ –µ—Å—Ç—å `full` - –ø–æ–∫–∞–∂–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é. –ï—Å–ª–∏ –Ω–µ—Ç - —Å–æ–±–µ—Ä–∏ –∏–∑ —á–∞—Å—Ç–µ–π (—Ä–µ–≥–∏–æ–Ω, –≥–æ—Ä–æ–¥, —É–ª–∏—Ü–∞, –¥–æ–º)

### 3. üë• –†–£–ö–û–í–û–î–°–¢–í–û
–¢–∞–±–ª–∏—Ü–∞ –í–°–ï–• —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π:
| –§–ò–û | –î–æ–ª–∂–Ω–æ—Å—Ç—å | –î–∞—Ç–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è | –ò–ù–ù |
|-----|-----------|-----------------|-----|

### 4. üíº –£–ß–†–ï–î–ò–¢–ï–õ–ò –ò –°–¢–†–£–ö–¢–£–†–ê –í–õ–ê–î–ï–ù–ò–Ø

#### –¢–∞–±–ª–∏—Ü–∞ —É—á—Ä–µ–¥–∏—Ç–µ–ª–µ–π:
| –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ | –¢–∏–ø | –ò–ù–ù | –î–æ–ª—è % |
|--------------|-----|-----|--------|

#### –°–µ—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π:
{network_diagram}

**–í–ê–ñ–ù–û: –î–∏–∞–≥—Ä–∞–º–º—É –≤—ã—à–µ –≤—Å—Ç–∞–≤—å –í –¢–û–ß–ù–û–°–¢–ò –∫–∞–∫ –µ—Å—Ç—å, –ù–ï –∏–∑–º–µ–Ω—è—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å Mermaid!**

**–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü: {len(related)}
- –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤–ª–∞–¥–µ–Ω–∏—è
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä—ã

### 5. üè≠ –í–ò–î–´ –î–ï–Ø–¢–ï–õ–¨–ù–û–°–¢–ò (–û–ö–í–≠–î)

**–û—Å–Ω–æ–≤–Ω–æ–π:**
–ö–æ–¥ –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ:**
–°–ø–∏—Å–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)

### 6. üí∞ –§–ò–ù–ê–ù–°–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò

#### –î–æ—Ö–æ–¥—ã –∏ —Ä–∞—Å—Ö–æ–¥—ã (–ø–æ –≥–æ–¥–∞–º):
–¢–∞–±–ª–∏—Ü–∞. –ï—Å–ª–∏ –º–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π ‚Üí "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ API"

#### –ù–∞–ª–æ–≥–∏ (–ø–æ –≥–æ–¥–∞–º):
–¢–∞–±–ª–∏—Ü–∞

#### –°—Ä–µ–¥–Ω–µ—Å–ø–∏—Å–æ—á–Ω–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å:
–¢–∞–±–ª–∏—Ü–∞ –ø–æ –≥–æ–¥–∞–º

#### –î—Ä—É–≥–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:
- –ù–∞–ª–æ–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã
- –†–∞–∑–º–µ—Ä –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
- –ì–æ—Å–ø–æ–¥–¥–µ—Ä–∂–∫–∞

### 7. üìä –ë–£–•–ì–ê–õ–¢–ï–†–°–ö–ê–Ø –û–¢–ß–ï–¢–ù–û–°–¢–¨

**–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π multi_year_data –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –°–í–û–î–ù–û–ô –¢–ê–ë–õ–ò–¶–´!**

**–î–ª—è —Ñ–∞–π–ª–æ–≤ —Å AI-–ê–ù–ê–õ–ò–ó–û–ú (—É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –ø–æ–ª–µ `analysis`):**

–ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ `multi_year_data` –∏ `analysis` –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞:

#### –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (—Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞):

–ü–æ—Å—Ç—Ä–æ–π —Ç–∞–±–ª–∏—Ü—É –ø–æ –í–°–ï–ú –≥–æ–¥–∞–º –∏–∑ –º–∞—Å—Å–∏–≤–∞ `years`:

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | {{–ì–æ–¥ 1}} | {{–ì–æ–¥ 2}} | {{–ì–æ–¥ 3}} | –ò–∑–º–µ–Ω–µ–Ω–∏–µ (%) |
|------------|---------|---------|---------|---------------|
| **–û–¢–ß–ï–¢ –û –§–ò–ù–ê–ù–°–û–í–´–• –†–ï–ó–£–õ–¨–¢–ê–¢–ê–•** | | | | |
| –í—ã—Ä—É—á–∫–∞ | ... | ... | ... | ... |
| –¢–µ–º–ø —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏, % | - | ... | ... | ... |
| –í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–∞–ª–æ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |
| –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |
| –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (—É–±—ã—Ç–æ–∫) | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |
| **–û–¢–ß–ï–¢ –û –§–ò–ù–ê–ù–°–û–í–û–ú –ü–û–õ–û–ñ–ï–ù–ò–ò (–ë–ê–õ–ê–ù–°)** | | | | |
| –ê–ö–¢–ò–í (–≤—Å–µ–≥–æ) | ... | ... | ... | ... |
| –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ó–∞–ø–∞—Å—ã | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∑–∞–ø–∞—Å–æ–≤, —Ä–∞–∑ | ... | ... | ... | ... |
| –î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | ... | ... | ... | ... |
| –î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è | ... | ... | ... | ... |
| –ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ) | ... | ... | ... | ... |
| –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã | ... | ... | ... | ... |
| –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | ... | ... | ... | ... |
| –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª | ... | ... | ... | ... |
| –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞, % | ... | ... | ... | ... |
| –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ | ... | ... | ... | ... |
| –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å, x | ... | ... | ... | ... |
| **–û–¢–ß–ï–¢ –û –î–í–ò–ñ–ï–ù–ò–ò –î–ï–ù–ï–ñ–ù–´–• –°–†–ï–î–°–¢–í** | | | | |
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –ò—Ç–æ–≥–æ–≤—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥ | ... | ... | ... | ... |
| –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ | ... | ... | ... | ... |
| –†–∞–∑–Ω–∏—Ü–∞: –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ - –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –û–° | ... | ... | ... | ... |

#### ü§ñ –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ò–ù–í–ï–°–¢-–ê–ù–ê–õ–ò–¢–ò–ö–ê:

**–§–∏–Ω–∞–Ω—Å–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:** {{analysis.financial_health}}

**–ö–ª—é—á–µ–≤—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã:**
–°–æ–∑–¥–∞–π —Ç–∞–±–ª–∏—Ü—É –∏–∑ `analysis.key_metrics` –∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –∏–∑ `multi_year_data`:

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ó–Ω–∞—á–µ–Ω–∏–µ | –ù–æ—Ä–º–∞ |
|------------|----------|-------|
| **–†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å** | | |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–∞–ª–æ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏, % | –ò–∑ multi_year_data.financial_results | >20% |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, % | –ò–∑ multi_year_data.financial_results | >10% |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏, % | –ò–∑ multi_year_data.financial_results | >5% |
| ROE (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–ø–∏—Ç–∞–ª–∞) | {{roe}} | >15% |
| ROA (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–æ–≤) | {{roa}} | >10% |
| **–†–æ—Å—Ç** | | |
| –¢–µ–º–ø —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏, % | –ò–∑ multi_year_data.financial_results | >5% |
| **–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å** | | |
| –ö–æ—ç—Ñ—Ñ. —Ç–µ–∫—É—â–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | {{current_ratio}} | >2.0 |
| –ö–æ—ç—Ñ—Ñ. –±—ã—Å—Ç—Ä–æ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | {{quick_ratio}} | >1.0 |
| –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞, % | –ò–∑ multi_year_data.balance | 5-15% |
| **–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å** | | |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∑–∞–ø–∞—Å–æ–≤, —Ä–∞–∑ | –ò–∑ multi_year_data.balance | >5 |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | –ò–∑ multi_year_data.balance | >10 |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | –ò–∑ multi_year_data.balance | >8 |
| **–î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞** | | |
| –î–æ–ª–≥/–ö–∞–ø–∏—Ç–∞–ª | {{debt_to_equity}} | <0.5 |
| –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å, x | –ò–∑ multi_year_data.balance | <3.0 |

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
–°–ø–∏—Å–æ–∫ –∏–∑ `analysis.strengths`

**–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:**
–°–ø–∏—Å–æ–∫ –∏–∑ `analysis.weaknesses`

**–†–∏—Å–∫–∏:**
–°–ø–∏—Å–æ–∫ –∏–∑ `analysis.risks` (–µ—Å–ª–∏ –µ—Å—Ç—å)

**–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:**
- **–†–µ–π—Ç–∏–Ω–≥:** {{analysis.investment_rating}}
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** {{analysis.investment_recommendation}}
- **–†–µ–∑—é–º–µ:** {{analysis.summary}}

---

**–î–ª—è —Ñ–∞–π–ª–æ–≤ –ë–ï–ó AI-–∞–Ω–∞–ª–∏–∑–∞ (—Å—Ç–∞—Ä—ã–µ XML —Ñ–∞–π–ª—ã):**

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ —Å multi_year_data:

#### –û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏ (–ë–∞–ª–∞–Ω—Å) - —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º:

–°–æ–∑–¥–∞–π –û–î–ù–£ —Ç–∞–±–ª–∏—Ü—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ì–æ–¥ 1 | –ì–æ–¥ 2 | –ì–æ–¥ 3 | –ò–∑–º–µ–Ω–µ–Ω–∏–µ (%) |
|------------|-------|-------|-------|---------------|
| –ê–ö–¢–ò–í (–≤—Å–µ–≥–æ) | ... | ... | ... | ... |
| –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ó–∞–ø–∞—Å—ã | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∑–∞–ø–∞—Å–æ–≤, —Ä–∞–∑ | ... | ... | ... | ... |
| –î–µ–±–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | ... | ... | ... | ... |
| –î–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è | ... | ... | ... | ... |
| –ü–ê–°–°–ò–í (–≤—Å–µ–≥–æ) | ... | ... | ... | ... |
| –ö–∞–ø–∏—Ç–∞–ª –∏ —Ä–µ–∑–µ—Ä–≤—ã | ... | ... | ... | ... |
| –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–µ–º–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ | ... | ... | ... | ... |
| –ö—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å | ... | ... | ... | ... |
| –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏, —Ä–∞–∑ | ... | ... | ... | ... |
| –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª | ... | ... | ... | ... |
| –û–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª / –í—ã—Ä—É—á–∫–∞, % | ... | ... | ... | ... |
| –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ | ... | ... | ... | ... |
| –ß–∏—Å—Ç—ã–π –¥–æ–ª–≥ / –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å, x | ... | ... | ... | ... |

#### –û—Ç—á–µ—Ç –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö (—Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞):

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ì–æ–¥ 1 | –ì–æ–¥ 2 | –ì–æ–¥ 3 | –ò–∑–º–µ–Ω–µ–Ω–∏–µ (%) |
|------------|-------|-------|-------|---------------|
| –í—ã—Ä—É—á–∫–∞ | ... | ... | ... | ... |
| –¢–µ–º–ø —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏, % | - | ... | ... | ... |
| –í–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–∞–ª–æ–≤–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |
| –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |
| –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (—É–±—ã—Ç–æ–∫) | ... | ... | ... | ... |
| –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏, % | ... | ... | ... | ... |

#### –û—Ç—á–µ—Ç –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –¥–µ–Ω–µ–∂–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ (—Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞):

| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ì–æ–¥ 1 | –ì–æ–¥ 2 | –ì–æ–¥ 3 | –ò–∑–º–µ–Ω–µ–Ω–∏–µ (%) |
|------------|-------|-------|-------|---------------|
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –°–∞–ª—å–¥–æ –ø–æ—Ç–æ–∫–æ–≤ –æ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | ... | ... | ... | ... |
| –ò—Ç–æ–≥–æ–≤—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –∑–∞ –ø–µ—Ä–∏–æ–¥ | ... | ... | ... | ... |
| –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ | ... | ... | ... | ... |
| –†–∞–∑–Ω–∏—Ü–∞: –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ - –ü—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –û–° | ... | ... | ... | ... |

**–ê–Ω–∞–ª–∏–∑:**
- –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π (—Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏, –ø—Ä–∏–±—ã–ª–∏)
- –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å (–ø–æ –≤–∞–ª–æ–≤–æ–π, –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π –∏ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏)
- –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å (–∑–∞–ø–∞—Å–æ–≤, –¥–µ–±–∏—Ç–æ—Ä—Å–∫–æ–π –∏ –∫—Ä–µ–¥–∏—Ç–æ—Ä—Å–∫–æ–π –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏)
- –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å (–æ–±–æ—Ä–æ—Ç–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏)
- –î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ (—á–∏—Å—Ç—ã–π –¥–æ–ª–≥, —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ–ª–≥/–∫–∞–ø–∏—Ç–∞–ª)
- –î–µ–Ω–µ–∂–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ (–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è, —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
- –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

### 8. ‚öñÔ∏è –°–£–î–ï–ë–ù–ê–Ø –ê–ö–¢–ò–í–ù–û–°–¢–¨

**–í—Å–µ–≥–æ –¥–µ–ª: {courts.get('total', 0)}** (–∏—Å—Ç–µ—Ü: {courts.get('plaintiff_total', 0)}, –æ—Ç–≤–µ—Ç—á–∏–∫: {courts.get('respondent_total', 0)}, —Ç—Ä–µ—Ç—å–µ –ª–∏—Ü–æ: {courts.get('third_party_total', 0)})

#### üìã –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –ò–°–¢–ï–¶ ({{courts.get('plaintiff_total', 0)}} –¥–µ–ª):

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ª–∞ —Å–æ–∑–¥–∞–π —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã —Å –ö–†–ê–¢–ö–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π:

| ‚Ññ –î–µ–ª–∞ | –¢–∏–ø | –°—É–¥ | –î–∞—Ç–∞ | –û—Ç–≤–µ—Ç—á–∏–∫–∏ | –°—É—Ç—å –¥–µ–ª–∞ | –î–µ—Ç–∞–ª–∏ |
|--------|-----|-----|------|-----------|-----------|--------|
| –ê40-123456/2024 | –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ | –ê–° –≥. –ú–æ—Å–∫–≤—ã | 2024-03-15 | –û–û–û –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç (–ò–ù–ù: 123...) | –í–∑—ã—Å–∫–∞–Ω–∏–µ –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏ 500 —Ç—ã—Å. —Ä—É–±. | [üìÑ PDF](URL) |

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ç–∞–±–ª–∏—Ü–µ:**
- –ù–æ–º–µ—Ä –¥–µ–ª–∞ –∏–∑ –ø–æ–ª—è `number`
- –¢–∏–ø –¥–µ–ª–∞ –∏–∑ –ø–æ–ª—è `case_type` (–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–µ/–ë–∞–Ω–∫—Ä–æ—Ç–Ω–æ–µ/–ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ)
- –°—É–¥ –∏–∑ –ø–æ–ª—è `court`
- –î–∞—Ç–∞ –∏–∑ –ø–æ–ª—è `start_date`
- –û—Ç–≤–µ—Ç—á–∏–∫–∏: –≤—ã–ø–∏—à–∏ –í–°–ï–• –∏–∑ –º–∞—Å—Å–∏–≤–∞ `respondents` —Å –∏—Ö –ò–ù–ù (—Ñ–æ—Ä–º–∞—Ç: "–ù–∞–∑–≤–∞–Ω–∏–µ (–ò–ù–ù: ...)")
- **–°—É—Ç—å –¥–µ–ª–∞: –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `summary` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ª–∞**
- **–î–µ—Ç–∞–ª–∏: –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `pdf_url` –¥–ª—è —Å—Å—ã–ª–∫–∏ –Ω–∞ PDF —Ä–µ—à–µ–Ω–∏—è. –ï—Å–ª–∏ `pdf_url` –µ—Å—Ç—å ‚Üí [üìÑ PDF](pdf_url), –µ—Å–ª–∏ –Ω–µ—Ç ‚Üí "PDF –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"**

**–ü–æ—Å–ª–µ —Ç–∞–±–ª–∏—Ü—ã –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑:**
- –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã (–∫—Ç–æ —á–∞—â–µ –æ—Ç–≤–µ—Ç—á–∏–∫)
- –¢–∏–ø—ã –¥–µ–ª (–∫–∞–∫–∏–µ –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç)

#### üìã –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –û–¢–í–ï–¢–ß–ò–ö ({{courts.get('respondent_total', 0)}} –¥–µ–ª):

–ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞, –Ω–æ –∫–æ–ª–æ–Ω–∫–∞ "–û—Ç–≤–µ—Ç—á–∏–∫–∏" –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "–ò—Å—Ç—Ü—ã":

| ‚Ññ –î–µ–ª–∞ | –¢–∏–ø | –°—É–¥ | –î–∞—Ç–∞ | –ò—Å—Ç—Ü—ã | –°—É—Ç—å –¥–µ–ª–∞ | –î–µ—Ç–∞–ª–∏ |
|--------|-----|-----|------|-------|-----------|--------|
| –ê41-789012/2023 | –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–µ | –ê–° –ú–û | 2023-11-10 | –û–û–û –ü–æ—Å—Ç–∞–≤—â–∏–∫ (–ò–ù–ù: 456...) | –í–æ–∑–º–µ—â–µ–Ω–∏–µ —É–±—ã—Ç–∫–æ–≤ 1.2 –º–ª–Ω —Ä—É–±. | [üìÑ PDF](URL) |

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- **–°—É—Ç—å –¥–µ–ª–∞: –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `summary` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ª–∞**
- **–î–µ—Ç–∞–ª–∏: –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `pdf_url` –¥–ª—è —Å—Å—ã–ª–∫–∏ –Ω–∞ PDF —Ä–µ—à–µ–Ω–∏—è. –ï—Å–ª–∏ `pdf_url` –µ—Å—Ç—å ‚Üí [üìÑ PDF](pdf_url), –µ—Å–ª–∏ –Ω–µ—Ç ‚Üí "PDF –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"**
- –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Ç–∞–±–ª–∏—Ü–µ –∏—Å—Ç—Ü–∞

**–ü–æ—Å–ª–µ —Ç–∞–±–ª–∏—Ü—ã –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑:**
- –û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å—Ç—Ü—ã (–∫—Ç–æ —á–∞—â–µ –ø–æ–¥–∞–µ—Ç –∏—Å–∫–∏)
- –¢–∏–ø—ã –¥–µ–ª (–∫–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç)
- –°—É–¥–µ–±–Ω—ã–µ —Ä–∏—Å–∫–∏

#### üìã –ö–æ–º–ø–∞–Ω–∏—è –∫–∞–∫ –¢–†–ï–¢–¨–ï –õ–ò–¶–û ({{courts.get('third_party_total', 0)}} –¥–µ–ª):

–ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ–ª–∞ (third_party_total > 0), —Å–æ–∑–¥–∞–π –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –æ–±–µ–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏:

| ‚Ññ –î–µ–ª–∞ | –¢–∏–ø | –°—É–¥ | –î–∞—Ç–∞ | –ò—Å—Ç—Ü—ã | –û—Ç–≤–µ—Ç—á–∏–∫–∏ | –°—É—Ç—å –¥–µ–ª–∞ | –î–µ—Ç–∞–ª–∏ |
|--------|-----|-----|------|-------|-----------|-----------|--------|

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- **–°—É—Ç—å –¥–µ–ª–∞: –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `summary` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–ª–∞**
- **–î–µ—Ç–∞–ª–∏: –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `pdf_url` –¥–ª—è —Å—Å—ã–ª–∫–∏ –Ω–∞ PDF —Ä–µ—à–µ–Ω–∏—è. –ï—Å–ª–∏ `pdf_url` –µ—Å—Ç—å ‚Üí [üìÑ PDF](pdf_url), –µ—Å–ª–∏ –Ω–µ—Ç ‚Üí "PDF –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"**

**–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ —Å—É–¥–µ–±–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:**
- –í—Å–µ–≥–æ –¥–µ–ª –∏ –¥–∏–Ω–∞–º–∏–∫–∞
- –ù–∞–∏–±–æ–ª–µ–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã
- –°—É–¥–µ–±–Ω—ã–µ —Ä–∏—Å–∫–∏ (–µ—Å–ª–∏ –∫–æ–º–ø–∞–Ω–∏—è —á–∞—Å—Ç–æ –æ—Ç–≤–µ—Ç—á–∏–∫)
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### 9. üì∞ –£–ü–û–ú–ò–ù–ê–ù–ò–Ø –í –°–ú–ò

**–ï—Å–ª–∏ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è (media –Ω–µ –ø—É—Å—Ç), —Å–æ–∑–¥–∞–π —Ä–∞–∑–¥–µ–ª:**

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫—É—é –∫–∞—Ä—Ç–æ—á–∫—É:

**–ó–∞–≥–æ–ª–æ–≤–æ–∫:** [–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏](URL)  
**–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:** –î–∞—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)  
**–ê–≤—Ç–æ—Ä:** –ò–º—è –∞–≤—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)  
**–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ `highlights` (–∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã) –∏–ª–∏ `text` (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤)

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–æ–ª—è `title` - —Å–¥–µ–ª–∞–π –∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ `url`
- –î–∞—Ç–∞ –∏–∑ –ø–æ–ª—è `published_date` 
- –ê–≤—Ç–æ—Ä –∏–∑ –ø–æ–ª—è `author`
- –î–ª—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π:
  1. –ï—Å–ª–∏ –µ—Å—Ç—å `highlights` - –≤—ã–≤–µ–¥–∏ –∏—Ö —Å–ø–∏—Å–∫–æ–º (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)
  2. –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ `text`
- –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö - –ø—Ä–æ–ø—É—Å—Ç–∏ —ç—Ç–æ –ø–æ–ª–µ

**–ü—Ä–∏–º–µ—Ä –∫–∞—Ä—Ç–æ—á–∫–∏:**

**–ó–∞–≥–æ–ª–æ–≤–æ–∫:** [–ö–æ–º–ø–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏–ª–∞ –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç](https://example.com/article)  
**–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:** 2024-11-15  
**–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**  
- –ö–æ–º–ø–∞–Ω–∏—è –æ–±—ä—è–≤–∏–ª–∞ –æ –∑–∞–ø—É—Å–∫–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å—é 50 –º–ª–Ω —Ä—É–±.
- –ü—Ä–æ–µ–∫—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
- –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è —Å–æ–∑–¥–∞–Ω–∏–µ 100 –Ω–æ–≤—ã—Ö —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç

---

**–ü–æ—Å–ª–µ –≤—Å–µ—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–æ–±–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑:**
- –û–±—â–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è)
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
- –î–∏–Ω–∞–º–∏–∫–∞ –º–µ–¥–∏–∞-–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –≤–∏–¥–Ω—ã –¥–∞—Ç—ã)

### 10. üéØ –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –û–¶–ï–ù–ö–ê

**–ù–∞ –æ—Å–Ω–æ–≤–µ –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**

#### –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:
- –ß—Ç–æ —Ö–æ—Ä–æ—à–µ–≥–æ –≤–∏–¥–Ω–æ –≤ —Ü–∏—Ñ—Ä–∞—Ö

#### –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:
- –ß—Ç–æ –Ω–∞—Å—Ç–æ—Ä–∞–∂–∏–≤–∞–µ—Ç

#### –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ä–∏—Å–∫–∏:
- –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≤–ª–∞–¥–µ–Ω–∏—è
- –°–≤—è–∑–∞–Ω–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
- –°—É–¥–µ–±–Ω—ã–µ —Ä–∏—Å–∫–∏

#### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö

**–ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞:** X/10 (–æ–±–æ—Å–Ω—É–π —Ü–∏—Ñ—Ä–∞–º–∏)

---

# –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{data_summary}

---

**–í–ê–ñ–ù–û:**
- –ï—Å–ª–∏ –≤–∏–¥–∏—à—å `null`, `None`, `[]` - –ø–∏—à–∏ "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ API"
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ
- –î–∏–∞–≥—Ä–∞–º–º–∞ —Å–µ—Ç–∏ —É–∂–µ –≥–æ—Ç–æ–≤–∞ - –≤—Å—Ç–∞–≤—å –µ—ë –∫–∞–∫ –µ—Å—Ç—å
- –í—Å–µ –≤—ã–≤–æ–¥—ã –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ü–∏—Ñ—Ä
- **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π multi_year_data –∏–∑ –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –°–í–û–î–ù–û–ô —Ç–∞–±–ª–∏—Ü—ã –ø–æ –≤—Å–µ–º –≥–æ–¥–∞–º**
- –ó–Ω–∞—á–µ–Ω–∏—è null –≤ —Ç–∞–±–ª–∏—Ü–µ –æ—Ç–æ–±—Ä–∞–∂–∞–π –∫–∞–∫ "-" (–ø—Ä–æ—á–µ—Ä–∫)
"""

    st.info("ü§ñ –§–æ—Ä–º–∞—Ç–∏—Ä—É—é –æ—Ç—á–µ—Ç...")
    
    try:
        time.sleep(3)
        response = model.generate_content(prompt)
        report = response.text or "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
        st.success("‚úÖ –ì–æ—Ç–æ–≤–æ")
    except Exception as e:
        report = f"–û—à–∏–±–∫–∞: {str(e)}"
        st.error(f"‚ùå {report}")
    
    return {"markdown_report": report}

# ==================== –ì–†–ê–§ ====================
@st.cache_resource
def build_workflow():
    workflow = StateGraph(AgentState)
    workflow.add_node("fetch_egrul", fetch_egrul_data)
    workflow.add_node("fetch_financial", fetch_financial_data)
    workflow.add_node("download_and_parse_boh", download_and_parse_boh)
    workflow.add_node("fetch_arbitration", fetch_arbitration_data)
    workflow.add_node("fetch_media", fetch_media_mentions)
    workflow.add_node("merge_and_analyze", merge_and_analyze)

    workflow.set_entry_point("fetch_egrul")
    workflow.add_edge("fetch_egrul", "fetch_financial")
    workflow.add_edge("fetch_financial", "download_and_parse_boh")
    workflow.add_edge("download_and_parse_boh", "fetch_arbitration")
    workflow.add_edge("fetch_arbitration", "fetch_media")
    workflow.add_edge("fetch_media", "merge_and_analyze")
    workflow.add_edge("merge_and_analyze", "__end__")
    
    return workflow.compile()

# ==================== UI ====================
def main():
    st.title("üìä –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏")
    st.caption("üöÄ –í–µ—Ä—Å–∏—è 3.14 - –î–æ–±–∞–≤–ª–µ–Ω—ã PDF —Ñ–∞–π–ª—ã —Ä–µ—à–µ–Ω–∏–π –ø–æ –¥–µ–ª–∞–º")
    st.markdown("---")
    
    with st.sidebar:
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
        
        # –í–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã
        st.success("**üöÄ –í–µ—Ä—Å–∏—è:** 3.14")
        st.caption("üìÑ –î–æ–±–∞–≤–ª–µ–Ω—ã PDF —Ä–µ—à–µ–Ω–∏–π –ø–æ –¥–µ–ª–∞–º")
        
        st.markdown("---")
        
        if PDF_LIB:
            st.success(f"‚úÖ PDF –±–∏–±–ª–∏–æ—Ç–µ–∫–∞: **{PDF_LIB}**")
        else:
            st.error("‚ùå –ù–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è PDF")
            st.code("pip install pdfplumber")
        
        st.markdown("---")
        
        st.info("""
        **üìã –ß—Ç–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º:**
        - –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ï–ì–†–Æ–õ)
        - –°–µ—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
        - –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        - –ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∞—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
        - –°—É–¥–µ–±–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        """)
        
        st.markdown("---")
        
        st.success("""
        **‚úÖ –ù–æ–≤–æ–µ –≤ v3.14:**
        - üìÑ PDF —Ñ–∞–π–ª—ã —Ä–µ—à–µ–Ω–∏–π –ø–æ –¥–µ–ª–∞–º
        - üîó –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        - ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ API kad.arbitr
        - üîß v3.13: –†–µ–∞–ª—å–Ω—ã–µ –ø–æ–ª—è API
        - ‚úÖ v3.11: –£–±—Ä–∞–Ω—ã –≤—Å–µ –ª–∏–º–∏—Ç—ã
        """)
        
        st.markdown("---")
        
        st.info("""
        **üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
        - –ë–ï–ó –∑–∞–≥–ª—É—à–µ–∫ –¥–∞–Ω–Ω—ã—Ö
        - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–≤—è–∑–µ–π –∫–æ–º–ø–∞–Ω–∏–π
        - –ü–∞—Ä—Å–∏–Ω–≥ XML (Windows-1251) –∏ PDF
        - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–∞–ª–∞–Ω—Å–∞
        - AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–ª—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
        """)
        
        st.markdown("---")
        
        st.warning("""
        **‚ö†Ô∏è –õ–∏–º–∏—Ç—ã API:**
        - 100 –∑–∞–ø—Ä–æ—Å–æ–≤/—Å—É—Ç–∫–∏
        - 1 –∞–Ω–∞–ª–∏–∑ ‚âà 8-10 –∑–∞–ø—Ä–æ—Å–æ–≤
        - ~10-12 –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ –¥–µ–Ω—å
        """)
        
        st.markdown("---")
        st.caption("Powered by Gemini AI")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    col1, col2 = st.columns([3, 1])
    
    with col1:
        inn = st.text_input(
            "üî¢ –í–≤–µ–¥–∏—Ç–µ –ò–ù–ù –∫–æ–º–ø–∞–Ω–∏–∏:",
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 7730588444",
            help="10-–∑–Ω–∞—á–Ω—ã–π –ò–ù–ù –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∏–ª–∏ 12-–∑–Ω–∞—á–Ω—ã–π –¥–ª—è –ò–ü"
        )
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_button = st.button("üöÄ –ê–Ω–∞–ª–∏–∑", type="primary", use_container_width=True)
    
    if analyze_button:
        if not inn or len(inn.strip()) < 10:
            st.error("‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ò–ù–ù (–º–∏–Ω–∏–º—É–º 10 —Ü–∏—Ñ—Ä)")
        else:
            inn_norm = normalize_inn(inn)
            st.info(f"üìå –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ò–ù–ù: **{inn_norm}**")
            
            st.markdown("---")
            st.subheader("üîÑ –ü—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞")
            
            initial_state = {
                "inn": inn,
                "egrul_parsed": {},
                "fin_parsed": {},
                "boh_parsed": [],
                "courts_parsed": {},
                "related_companies": [],
                "markdown_report": ""
            }
            
            with st.spinner("‚è≥ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–π–º–µ—Ç 3-5 –º–∏–Ω—É—Ç..."):
                try:
                    app = build_workflow()
                    result = app.invoke(initial_state)
                    
                    st.markdown("---")
                    st.subheader("üìã –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç")
                    
                    # –†–µ–Ω–¥–µ—Ä–∏–º –æ—Ç—á–µ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Mermaid –¥–∏–∞–≥—Ä–∞–º–º
                    report_parts = result["markdown_report"].split("```mermaid")
                    
                    st.markdown(report_parts[0])  # –ß–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é mermaid –¥–∏–∞–≥—Ä–∞–º–º—É
                    for i in range(1, len(report_parts)):
                        part = report_parts[i]
                        diagram_end = part.find("```")
                        
                        if diagram_end != -1:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –¥–∏–∞–≥—Ä–∞–º–º—ã
                            diagram_code = part[:diagram_end].strip()
                            remaining_text = part[diagram_end + 3:]
                            
                            # –†–µ–Ω–¥–µ—Ä–∏–º Mermaid —á–µ—Ä–µ–∑ mermaid.ink API
                            try:
                                import base64
                                graphbytes = diagram_code.encode("utf8")
                                base64_bytes = base64.b64encode(graphbytes)
                                base64_string = base64_bytes.decode("ascii")
                                img_url = f"https://mermaid.ink/img/{base64_string}"
                                
                                st.image(img_url, caption="–°–µ—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π", use_container_width=True)
                            except Exception as e:
                                # Fallback: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–¥
                                st.code(diagram_code, language="mermaid")
                                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–Ω–¥–µ—Ä–∏—Ç—å –¥–∏–∞–≥—Ä–∞–º–º—É: {e}")
                            
                            # –û—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –¥–∏–∞–≥—Ä–∞–º–º—ã
                            st.markdown(remaining_text)
                        else:
                            st.markdown(part)
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    st.markdown("---")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.download_button(
                            "üíæ –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç (.md)",
                            result["markdown_report"].encode('utf-8'),
                            f"report_{inn_norm}.md",
                            "text/markdown",
                            use_container_width=True
                        )
                    
                    with col2:
                        st.link_button(
                            "üìä –ë—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å –Ω–∞ —Å–∞–π—Ç–µ",
                            f"{BASE_BOH_URL}ls.php?inn={inn_norm}",
                            use_container_width=True
                        )
                    
                    with col3:
                        # –°–∫–∞—á–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
                        raw_data = {
                            "egrul": result.get("egrul_parsed", {}),
                            "fin": result.get("fin_parsed", {}),
                            "boh": result.get("boh_parsed", []),
                            "courts": result.get("courts_parsed", {}),
                            "related": result.get("related_companies", [])
                        }
                        st.download_button(
                            "üìÑ –°–∫–∞—á–∞—Ç—å JSON",
                            json.dumps(raw_data, ensure_ascii=False, indent=2).encode('utf-8'),
                            f"data_{inn_norm}.json",
                            "application/json",
                            use_container_width=True
                        )
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    st.markdown("---")
                    st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        related_count = len(result.get("related_companies", []))
                        st.metric("–°–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏", related_count)
                    
                    with col2:
                        boh_success = len([f for f in result.get("boh_parsed", []) if f.get("success")])
                        boh_total = len(result.get("boh_parsed", []))
                        st.metric("–§–∞–π–ª—ã –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏", f"{boh_success}/{boh_total}")
                    
                    with col3:
                        courts_total = result.get("courts_parsed", {}).get("total", 0)
                        st.metric("–°—É–¥–µ–±–Ω—ã—Ö –¥–µ–ª", courts_total)
                    
                    with col4:
                        fin_records = len(result.get("fin_parsed", {}).get("income_expenses", []))
                        st.metric("–§–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π", fin_records)
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
                    st.exception(e)
    
    # –§—É—Ç–µ—Ä
    st.markdown("---")
    st.caption("‚ö†Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö: egrul.itsoft.ru, parser-api.com | –í–µ—Ä—Å–∏—è 3.0 —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º –±—É—Ö–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏")

if __name__ == "__main__":
    main()